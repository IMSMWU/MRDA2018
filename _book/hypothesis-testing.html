<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Marketing Research Design &amp; Analysis 2018</title>
  <meta name="description" content="An Introduction to Statistics Using R">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Marketing Research Design &amp; Analysis 2018" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An Introduction to Statistics Using R" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Marketing Research Design &amp; Analysis 2018" />
  
  <meta name="twitter:description" content="An Introduction to Statistics Using R" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
<link rel="prev" href="introduction-to-statistical-inference.html">
<link rel="next" href="regression.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./">MRDA 2018</a></strong></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome!</a></li>
<li class="chapter" data-level="" data-path="course-materials.html"><a href="course-materials.html"><i class="fa fa-check"></i>Course materials</a><ul>
<li class="chapter" data-level="" data-path="course-materials.html"><a href="course-materials.html#main-reference"><i class="fa fa-check"></i>Main reference</a></li>
<li class="chapter" data-level="" data-path="course-materials.html"><a href="course-materials.html#further-readings"><i class="fa fa-check"></i>Further readings</a></li>
<li class="chapter" data-level="" data-path="course-materials.html"><a href="course-materials.html#datacamp"><i class="fa fa-check"></i>DataCamp</a></li>
<li class="chapter" data-level="" data-path="course-materials.html"><a href="course-materials.html#other-web-resources"><i class="fa fa-check"></i>Other web-resources</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting started</a><ul>
<li class="chapter" data-level="1.1" data-path="getting-started.html"><a href="getting-started.html#how-to-download-and-install-r-and-rstudio"><i class="fa fa-check"></i><b>1.1</b> How to download and install R and RStudio</a></li>
<li class="chapter" data-level="1.2" data-path="getting-started.html"><a href="getting-started.html#getting-help"><i class="fa fa-check"></i><b>1.2</b> Getting help</a></li>
<li class="chapter" data-level="1.3" data-path="getting-started.html"><a href="getting-started.html#functions"><i class="fa fa-check"></i><b>1.3</b> Functions</a></li>
<li class="chapter" data-level="1.4" data-path="getting-started.html"><a href="getting-started.html#packages"><i class="fa fa-check"></i><b>1.4</b> Packages</a></li>
<li class="chapter" data-level="1.5" data-path="getting-started.html"><a href="getting-started.html#a-typical-r-session"><i class="fa fa-check"></i><b>1.5</b> A typical R session</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-handling.html"><a href="data-handling.html"><i class="fa fa-check"></i><b>2</b> Data handling</a><ul>
<li class="chapter" data-level="2.1" data-path="data-handling.html"><a href="data-handling.html#basic-data-handling"><i class="fa fa-check"></i><b>2.1</b> Basic data handling</a><ul>
<li class="chapter" data-level="2.1.1" data-path="data-handling.html"><a href="data-handling.html#creating-objects"><i class="fa fa-check"></i><b>2.1.1</b> Creating objects</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-handling.html"><a href="data-handling.html#data-types"><i class="fa fa-check"></i><b>2.1.2</b> Data types</a></li>
<li class="chapter" data-level="2.1.3" data-path="data-handling.html"><a href="data-handling.html#data-structures"><i class="fa fa-check"></i><b>2.1.3</b> Data structures</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-handling.html"><a href="data-handling.html#advanced-data-handling"><i class="fa fa-check"></i><b>2.2</b> Advanced data handling</a><ul>
<li class="chapter" data-level="2.2.1" data-path="data-handling.html"><a href="data-handling.html#the-dplyr-package"><i class="fa fa-check"></i><b>2.2.1</b> The dplyr package</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-handling.html"><a href="data-handling.html#dealing-with-strings"><i class="fa fa-check"></i><b>2.2.2</b> Dealing with strings</a></li>
<li class="chapter" data-level="2.2.3" data-path="data-handling.html"><a href="data-handling.html#case-study"><i class="fa fa-check"></i><b>2.2.3</b> Case study</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-handling.html"><a href="data-handling.html#data-import-and-export"><i class="fa fa-check"></i><b>2.3</b> Data import and export</a><ul>
<li class="chapter" data-level="2.3.1" data-path="data-handling.html"><a href="data-handling.html#getting-data-for-this-course"><i class="fa fa-check"></i><b>2.3.1</b> Getting data for this course</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-handling.html"><a href="data-handling.html#import-data-created-by-other-software-packages"><i class="fa fa-check"></i><b>2.3.2</b> Import data created by other software packages</a></li>
<li class="chapter" data-level="2.3.3" data-path="data-handling.html"><a href="data-handling.html#export-data"><i class="fa fa-check"></i><b>2.3.3</b> Export data</a></li>
<li class="chapter" data-level="2.3.4" data-path="data-handling.html"><a href="data-handling.html#import-data-from-the-web"><i class="fa fa-check"></i><b>2.3.4</b> Import data from the Web</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="summarizing-data.html"><a href="summarizing-data.html"><i class="fa fa-check"></i><b>3</b> Summarizing data</a><ul>
<li class="chapter" data-level="3.1" data-path="summarizing-data.html"><a href="summarizing-data.html#summary-statistics"><i class="fa fa-check"></i><b>3.1</b> Summary statistics</a><ul>
<li class="chapter" data-level="3.1.1" data-path="summarizing-data.html"><a href="summarizing-data.html#categorical-variables"><i class="fa fa-check"></i><b>3.1.1</b> Categorical variables</a></li>
<li class="chapter" data-level="3.1.2" data-path="summarizing-data.html"><a href="summarizing-data.html#continuous-variables"><i class="fa fa-check"></i><b>3.1.2</b> Continuous variables</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="summarizing-data.html"><a href="summarizing-data.html#data-visualization"><i class="fa fa-check"></i><b>3.2</b> Data visualization</a><ul>
<li class="chapter" data-level="3.2.1" data-path="summarizing-data.html"><a href="summarizing-data.html#categorical-variables-1"><i class="fa fa-check"></i><b>3.2.1</b> Categorical variables</a></li>
<li class="chapter" data-level="3.2.2" data-path="summarizing-data.html"><a href="summarizing-data.html#continuous-variables-1"><i class="fa fa-check"></i><b>3.2.2</b> Continuous variables</a></li>
<li class="chapter" data-level="3.2.3" data-path="summarizing-data.html"><a href="summarizing-data.html#saving-plots"><i class="fa fa-check"></i><b>3.2.3</b> Saving plots</a></li>
<li class="chapter" data-level="3.2.4" data-path="summarizing-data.html"><a href="summarizing-data.html#additional-options"><i class="fa fa-check"></i><b>3.2.4</b> Additional options</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="summarizing-data.html"><a href="summarizing-data.html#writing-reports-using-r-markdown"><i class="fa fa-check"></i><b>3.3</b> Writing reports using R-Markdown</a><ul>
<li class="chapter" data-level="3.3.1" data-path="summarizing-data.html"><a href="summarizing-data.html#creating-a-new-r-markdown-document"><i class="fa fa-check"></i><b>3.3.1</b> Creating a new R-Markdown document</a></li>
<li class="chapter" data-level="3.3.2" data-path="summarizing-data.html"><a href="summarizing-data.html#text-and-equations"><i class="fa fa-check"></i><b>3.3.2</b> Text and Equations</a></li>
<li class="chapter" data-level="3.3.3" data-path="summarizing-data.html"><a href="summarizing-data.html#r-code"><i class="fa fa-check"></i><b>3.3.3</b> R-Code</a></li>
<li class="chapter" data-level="3.3.4" data-path="summarizing-data.html"><a href="summarizing-data.html#latex-math"><i class="fa fa-check"></i><b>3.3.4</b> LaTeX Math</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-statistical-inference.html"><a href="introduction-to-statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Introduction to Statistical Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-statistical-inference.html"><a href="introduction-to-statistical-inference.html#if-we-knew-it-all"><i class="fa fa-check"></i><b>4.1</b> If we knew it all</a><ul>
<li class="chapter" data-level="4.1.1" data-path="introduction-to-statistical-inference.html"><a href="introduction-to-statistical-inference.html#sampling-from-a-known-population"><i class="fa fa-check"></i><b>4.1.1</b> Sampling from a known population</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-statistical-inference.html"><a href="introduction-to-statistical-inference.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>4.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-statistical-inference.html"><a href="introduction-to-statistical-inference.html#using-what-we-actually-know"><i class="fa fa-check"></i><b>4.3</b> Using what we actually know</a><ul>
<li class="chapter" data-level="4.3.1" data-path="introduction-to-statistical-inference.html"><a href="introduction-to-statistical-inference.html#confidence-intervals-for-the-sample-mean"><i class="fa fa-check"></i><b>4.3.1</b> Confidence Intervals for the Sample Mean</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="introduction-to-statistical-inference.html"><a href="introduction-to-statistical-inference.html#summary"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>5</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a><ul>
<li class="chapter" data-level="5.1.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#why-do-we-test-hypotheses"><i class="fa fa-check"></i><b>5.1.1</b> Why do we test hypotheses?</a></li>
<li class="chapter" data-level="5.1.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-process-of-hypothesis-testing"><i class="fa fa-check"></i><b>5.1.2</b> The process of hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#parametric-tests"><i class="fa fa-check"></i><b>5.2</b> Parametric tests</a><ul>
<li class="chapter" data-level="5.2.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#independent-means-t-test"><i class="fa fa-check"></i><b>5.2.1</b> Independent-means t-test</a></li>
<li class="chapter" data-level="5.2.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#dependent-means-t-test"><i class="fa fa-check"></i><b>5.2.2</b> Dependent-means t-test</a></li>
<li class="chapter" data-level="5.2.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#one-sample-t-test"><i class="fa fa-check"></i><b>5.2.3</b> One-sample t-test</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-tests"><i class="fa fa-check"></i><b>5.3</b> Non-parametric tests</a><ul>
<li class="chapter" data-level="5.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#mann-whitney-u-test-a.k.a.-wilcoxon-rank-sum-test"><i class="fa fa-check"></i><b>5.3.1</b> Mann-Whitney U Test (a.k.a. Wilcoxon rank-sum test)</a></li>
<li class="chapter" data-level="5.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>5.3.2</b> Wilcoxon signed-rank test</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#categorical-data"><i class="fa fa-check"></i><b>5.4</b> Categorical data</a><ul>
<li class="chapter" data-level="5.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#comparing-proportions"><i class="fa fa-check"></i><b>5.4.1</b> Comparing proportions</a></li>
<li class="chapter" data-level="5.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#chi-square-test"><i class="fa fa-check"></i><b>5.4.2</b> Chi-square test</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#analysis-of-variance"><i class="fa fa-check"></i><b>5.5</b> Analysis of variance</a><ul>
<li class="chapter" data-level="5.5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#introduction-1"><i class="fa fa-check"></i><b>5.5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.5.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#decomposing-variance"><i class="fa fa-check"></i><b>5.5.2</b> Decomposing variance</a></li>
<li class="chapter" data-level="5.5.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#one-way-anova"><i class="fa fa-check"></i><b>5.5.3</b> One-way ANOVA</a></li>
<li class="chapter" data-level="5.5.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#n-way-anova"><i class="fa fa-check"></i><b>5.5.4</b> N-way ANOVA</a></li>
<li class="chapter" data-level="5.5.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#non-parametric-tests-1"><i class="fa fa-check"></i><b>5.5.5</b> Non-parametric tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>6</b> Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="regression.html"><a href="regression.html#correlation"><i class="fa fa-check"></i><b>6.1</b> Correlation</a><ul>
<li class="chapter" data-level="6.1.1" data-path="regression.html"><a href="regression.html#correlation-coefficient"><i class="fa fa-check"></i><b>6.1.1</b> Correlation coefficient</a></li>
<li class="chapter" data-level="6.1.2" data-path="regression.html"><a href="regression.html#significance-testing"><i class="fa fa-check"></i><b>6.1.2</b> Significance testing</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="regression.html"><a href="regression.html#regression-1"><i class="fa fa-check"></i><b>6.2</b> Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="regression.html"><a href="regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>6.2.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="6.2.2" data-path="regression.html"><a href="regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>6.2.2</b> Multiple linear regression</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regression.html"><a href="regression.html#potential-problems"><i class="fa fa-check"></i><b>6.3</b> Potential problems</a><ul>
<li class="chapter" data-level="6.3.1" data-path="regression.html"><a href="regression.html#outliers"><i class="fa fa-check"></i><b>6.3.1</b> Outliers</a></li>
<li class="chapter" data-level="6.3.2" data-path="regression.html"><a href="regression.html#influential-observations"><i class="fa fa-check"></i><b>6.3.2</b> Influential observations</a></li>
<li class="chapter" data-level="6.3.3" data-path="regression.html"><a href="regression.html#non-linearity"><i class="fa fa-check"></i><b>6.3.3</b> Non-linearity</a></li>
<li class="chapter" data-level="6.3.4" data-path="regression.html"><a href="regression.html#non-constant-error-variance"><i class="fa fa-check"></i><b>6.3.4</b> Non-constant error variance</a></li>
<li class="chapter" data-level="6.3.5" data-path="regression.html"><a href="regression.html#non-normally-distributed-errors"><i class="fa fa-check"></i><b>6.3.5</b> Non-normally distributed errors</a></li>
<li class="chapter" data-level="6.3.6" data-path="regression.html"><a href="regression.html#correlation-of-errors"><i class="fa fa-check"></i><b>6.3.6</b> Correlation of errors</a></li>
<li class="chapter" data-level="6.3.7" data-path="regression.html"><a href="regression.html#collinearity"><i class="fa fa-check"></i><b>6.3.7</b> Collinearity</a></li>
<li class="chapter" data-level="6.3.8" data-path="regression.html"><a href="regression.html#omitted-variables"><i class="fa fa-check"></i><b>6.3.8</b> Omitted Variables</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="regression.html"><a href="regression.html#categorical-predictors"><i class="fa fa-check"></i><b>6.4</b> Categorical predictors</a><ul>
<li class="chapter" data-level="6.4.1" data-path="regression.html"><a href="regression.html#two-categories"><i class="fa fa-check"></i><b>6.4.1</b> Two categories</a></li>
<li class="chapter" data-level="6.4.2" data-path="regression.html"><a href="regression.html#more-than-two-categories"><i class="fa fa-check"></i><b>6.4.2</b> More than two categories</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="regression.html"><a href="regression.html#extensions-of-the-linear-model"><i class="fa fa-check"></i><b>6.5</b> Extensions of the linear model</a><ul>
<li class="chapter" data-level="6.5.1" data-path="regression.html"><a href="regression.html#interaction-effects"><i class="fa fa-check"></i><b>6.5.1</b> Interaction effects</a></li>
<li class="chapter" data-level="6.5.2" data-path="regression.html"><a href="regression.html#non-linear-relationships"><i class="fa fa-check"></i><b>6.5.2</b> Non-linear relationships</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="regression.html"><a href="regression.html#logistic-regression"><i class="fa fa-check"></i><b>6.6</b> Logistic regression</a><ul>
<li class="chapter" data-level="6.6.1" data-path="regression.html"><a href="regression.html#motivation-and-intuition"><i class="fa fa-check"></i><b>6.6.1</b> Motivation and intuition</a></li>
<li class="chapter" data-level="6.6.2" data-path="regression.html"><a href="regression.html#technical-details-of-the-model"><i class="fa fa-check"></i><b>6.6.2</b> Technical details of the model</a></li>
<li class="chapter" data-level="6.6.3" data-path="regression.html"><a href="regression.html#estimation-in-r"><i class="fa fa-check"></i><b>6.6.3</b> Estimation in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html"><i class="fa fa-check"></i><b>7</b> Exploratory factor analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#introduction-2"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#steps-in-factor-analysis"><i class="fa fa-check"></i><b>7.2</b> Steps in factor analysis</a><ul>
<li class="chapter" data-level="7.2.1" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#are-the-assumptions-satisfied"><i class="fa fa-check"></i><b>7.2.1</b> Are the assumptions satisfied?</a></li>
<li class="chapter" data-level="7.2.2" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#deriving-factors"><i class="fa fa-check"></i><b>7.2.2</b> Deriving factors</a></li>
<li class="chapter" data-level="7.2.3" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#factor-interpretation"><i class="fa fa-check"></i><b>7.2.3</b> Factor interpretation</a></li>
<li class="chapter" data-level="7.2.4" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#creating-new-variables"><i class="fa fa-check"></i><b>7.2.4</b> Creating new variables</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="exploratory-factor-analysis.html"><a href="exploratory-factor-analysis.html#reliability-analysis"><i class="fa fa-check"></i><b>7.3</b> Reliability analysis</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>8</b> Appendix</a><ul>
<li class="chapter" data-level="8.1" data-path="appendix.html"><a href="appendix.html#random-variables-probability-distributions"><i class="fa fa-check"></i><b>8.1</b> Random Variables &amp; Probability Distributions</a><ul>
<li class="chapter" data-level="8.1.1" data-path="appendix.html"><a href="appendix.html#random-variables"><i class="fa fa-check"></i><b>8.1.1</b> Random variables</a></li>
<li class="chapter" data-level="8.1.2" data-path="appendix.html"><a href="appendix.html#probability-distributions"><i class="fa fa-check"></i><b>8.1.2</b> Probability Distributions</a></li>
<li class="chapter" data-level="8.1.3" data-path="appendix.html"><a href="appendix.html#appendix-1"><i class="fa fa-check"></i><b>8.1.3</b> Appendix</a></li>
<li class="chapter" data-level="8.1.4" data-path="appendix.html"><a href="appendix.html#linear-regression"><i class="fa fa-check"></i><b>8.1.4</b> Linear regression</a></li>
<li class="chapter" data-level="8.1.5" data-path="appendix.html"><a href="appendix.html#logistic-regression-1"><i class="fa fa-check"></i><b>8.1.5</b> Logistic regression</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Marketing Research Design &amp; Analysis 2018</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1">
<h1><span class="header-section-number">5</span> Hypothesis testing</h1>
<p>This chapter is primarily based on Field, A., Miles J., &amp; Field, Z. (2012): Discovering Statistics Using R. Sage Publications, <strong>chapters 5, 9, 15, 18</strong>.</p>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<div id="why-do-we-test-hypotheses" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Why do we test hypotheses?</h3>
<p>We test hypotheses because we are confined to taking samples – we rarely work with the entire population. A sample that we take is likely to be different from a second sample that we take from the same population, so we use hypothesis tests to generalize from the sample to the population. However, we need some measure of uncertainty we can assign to analytic results. We use the standard error (i.e., the standard deviation of a large number of hypothetical samples) to gauge how well a particular sample represents the population. This is shown in the following figure.</p>
<div class="figure">
<img src="https://github.com/IMSMWU/Teaching/raw/master/MRDA2017/samplingdistribution.JPG" alt="Sampling distribution (source: Field, A. et al. (2012): Discovering Statistics Using R, p. 44)" />
<p class="caption">Sampling distribution (source: Field, A. et al. (2012): Discovering Statistics Using R, p. 44)</p>
</div>
<p>Recall the definition of the standard error (SE):</p>
<span class="math display" id="eq:SE">\[\begin{equation} 
\begin{split}
SE = \frac{s}{\sqrt{n}}
\end{split}
\tag{5.1}
\end{equation}\]</span>
<p>where <code>s</code> is the standard deviation and <code>n</code> is the number of observations in our sample. If the standard error is low, then we expect most samples to have similar means. If the standard error is large, large differences in sample means are more likely. If the difference in sample means is large, then we would expect based on the standard error that either the collected samples may be atypical of the population, or that the samples come from different populations but are typical of their respective population.</p>
<p>Note that there is a relationship between the sample size and the standard error. The larger the sample size, the smaller the standard error. This can be attributed to the fact that with larger samples, there is less uncertainty that the sample is a good approximation of the entire population.</p>
<p>The following plot shows the relationship between the sample size and the standard error. A hypothetical population of 1,000,000 observations is simulated and samples of ascending size are randomly drawn from this population. You can see that the standard error is decreasing with the number of observations.</p>
<p><br></p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-165"></span>
<img src="_main_files/figure-html/unnamed-chunk-165-1.png" alt="Relationship between the sample size and the standard error" width="672" />
<p class="caption">
Figure 5.1: Relationship between the sample size and the standard error
</p>
</div>
<p>Why is this important? Well, the generalized equation for calculating a test statistic is given by</p>
<span class="math display" id="eq:teststatistic">\[\begin{equation} 
\begin{split}
test\ statistic = \frac{effect}{error}
\end{split}
\tag{5.2}
\end{equation}\]</span>
<p>where <code>effect</code> denotes the effect that you are investigating (e.g., the mean difference in an outcome variable between two experimental groups), while <code>error</code> denotes the variation we would naturally expect to find based on the variability in the data and the sample size (e.g., the standard error of the mean difference). When the standard error is lower, the test statistic gets larger and you are more likely to obtain a significant test result. Hence - all else being equal - when you increase your sample size, this will increase the value of your test statistic (i.e., decrease the p-value).</p>
<p><br></p>
</div>
<div id="the-process-of-hypothesis-testing" class="section level3">
<h3><span class="header-section-number">5.1.2</span> The process of hypothesis testing</h3>
<p>The process of hypothesis testing consists of 6 consecutive steps:</p>
<ol style="list-style-type: decimal">
<li>Formulate null and alternative hypotheses</li>
<li>Select an appropriate test</li>
<li>Choose the level of significance (α)</li>
<li>Collect data and calculate the test statistic (T<sub>CAL</sub>)</li>
<li>Reject or do not reject H<sub>0</sub></li>
<li>Report results and draw a marketing conclusion</li>
</ol>
<p>In the following, we will use an example to go through the individual steps.</p>
</div>
</div>
<div id="parametric-tests" class="section level2">
<h2><span class="header-section-number">5.2</span> Parametric tests</h2>
<p>The first basic differentiation we can make is between parametric and non-parametric tests.</p>
<p><b>Parametric tests</b> require that variables are measured on an interval or ratio scale and that the data follows a known distribution. Particularly, tests based on the normal distribution (e.g., the t-test) require four basic assumptions:</p>
<ul>
<li>A normally distributed sampling distribution</li>
<li>Interval or ratio data</li>
</ul>
<p>And in addition for independent tests:</p>
<ul>
<li>Scores in different conditions are independent (because they come from different people)</li>
<li>Homogeneity of variance</li>
</ul>
<p><b>Non-Parametric tests</b> on the other hand do not require the sampling distribution to be normally distributed (a.k.a. “assumption free tests”). These tests may be used when the variable of interest is measured on an ordinal scale or when the parametric assumptions do not hold. They often rely on ranking the data instead of analyzing the actual scores. By ranking the data, information on the magnitude of differences is lost. Thus, parametric tests are more powerful if the sampling distribution is normally distributed.</p>
<div id="independent-means-t-test" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Independent-means t-test</h3>
<p>As an example of a parametric test, we will discuss the independent- and dependent-means t-test. The <b>independent-means t-test</b> is used when there are two experimental conditions and different units (e.g., participants, products) were assigned to each condition, while the <b>dependent-means t-test</b> is used when there are two experimental conditions and the same units (e.g., participants, products) were observed in both experimental conditions.</p>
<p><b>Example case:</b> What is the effect of price promotions on the sales of music albums?</p>
<p><b>Experimental setup:</b> As a marketing manager of a music download store, you are interested in the effect of price on demand. In the music download store, new releases were randomly assigned to an experimental group and sold at a reduced price (i.e., 7.95€), or a control group and sold at the standard price (9.95€). A representative sample of 102 new releases were sampled and these albums were randomly assigned to the experimental groups (i.e., 51 albums per group). The sales were tracked over one day.</p>
<p>Let’s load and investigate the data first:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(psych)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(Hmisc)
<span class="kw">rm</span>(music_sales)
music_sales &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/music_experiment.dat&quot;</span>, 
    <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)  <span class="co">#read in data</span>
music_sales<span class="op">$</span>group &lt;-<span class="st"> </span><span class="kw">factor</span>(music_sales<span class="op">$</span>group, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>), 
    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;low_price&quot;</span>, <span class="st">&quot;high_price&quot;</span>))  <span class="co">#convert grouping variable to factor</span>
<span class="kw">str</span>(music_sales)  <span class="co">#inspect data</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    102 obs. of  3 variables:
##  $ product_id: int  1 2 3 4 5 6 7 8 9 10 ...
##  $ unit_sales: int  6 27 30 24 21 11 18 15 18 13 ...
##  $ group     : Factor w/ 2 levels &quot;low_price&quot;,&quot;high_price&quot;: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(music_sales)  <span class="co">#inspect data</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["product_id"],"name":[1],"type":["int"],"align":["right"]},{"label":["unit_sales"],"name":[2],"type":["int"],"align":["right"]},{"label":["group"],"name":[3],"type":["fctr"],"align":["left"]}],"data":[{"1":"1","2":"6","3":"low_price"},{"1":"2","2":"27","3":"low_price"},{"1":"3","2":"30","3":"low_price"},{"1":"4","2":"24","3":"low_price"},{"1":"5","2":"21","3":"low_price"},{"1":"6","2":"11","3":"low_price"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Inspect frequencies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(music_sales<span class="op">$</span>unit_sales, music_sales<span class="op">$</span>group)  <span class="co">#frequencies</span></code></pre></div>
<pre><code>##     
##      low_price high_price
##   0          0          7
##   1          0          1
##   2          2          4
##   3          8         16
##   4          4          0
##   5          2          0
##   6         18          9
##   9          3          6
##   10         1          0
##   11         1          0
##   12         3          3
##   13         1          0
##   15         2          2
##   18         2          1
##   20         0          1
##   21         1          0
##   24         1          0
##   27         1          0
##   30         1          1</code></pre>
<p>Inspect descriptives (overall and by group).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">psych<span class="op">::</span><span class="kw">describe</span>(music_sales<span class="op">$</span>unit_sales)  <span class="co">#overall descriptives</span></code></pre></div>
<pre><code>##    vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 102 7.12 6.26      6     6.1 4.45   0  30    30 1.71     3.02 0.62</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">describeBy</span>(music_sales<span class="op">$</span>unit_sales, music_sales<span class="op">$</span>group)  <span class="co">#descriptives by group</span></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: low_price
##    vars  n mean   sd median trimmed  mad min max range skew kurtosis  se
## X1    1 51 8.37 6.44      6    7.17 4.45   2  30    28 1.66     2.22 0.9
## -------------------------------------------------------- 
## group: high_price
##    vars  n mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 51 5.86 5.87      3     4.9 4.45   0  30    30 1.84      4.1 0.82</code></pre>
<p>Create boxplot and plot of means.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(music_sales, <span class="kw">aes</span>(<span class="dt">x =</span> group, <span class="dt">y =</span> unit_sales)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Experimental group&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Number of sales&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>() </code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-169"></span>
<img src="_main_files/figure-html/unnamed-chunk-169-1.png" alt="Boxplot" width="672" />
<p class="caption">
Figure 5.2: Boxplot
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(music_sales, <span class="kw">aes</span>(group, unit_sales)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;summary&quot;</span>,  <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">width =</span> <span class="fl">0.7</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">stat =</span> <span class="st">&quot;summary&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Group&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Average number of sales&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-169"></span>
<img src="_main_files/figure-html/unnamed-chunk-169-2.png" alt="Plot of means" width="672" />
<p class="caption">
Figure 5.2: Plot of means
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(music_sales,<span class="kw">aes</span>(unit_sales)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">4</span>, <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;darkblue&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>group) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Number of sales&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Frequency&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-169"></span>
<img src="_main_files/figure-html/unnamed-chunk-169-3.png" alt="Histogram" width="672" />
<p class="caption">
Figure 5.2: Histogram
</p>
</div>
<p>There appears to be a difference between the two groups. The question is: is this difference statistically significant, or would we expect to observe a difference of this magnitude by chance given the sample size and variability in the data?</p>
<p>Let’s test this using a statistical test!</p>
<div id="formulate-null-and-alternative-hypothesis" class="section level4">
<h4><span class="header-section-number">5.2.1.1</span> Formulate null and alternative hypothesis</h4>
<p>What do we mean by null and alternative hypothesis?</p>
<p><b>Null Hypothesis (H<sub>0</sub>):</b></p>
<ul>
<li>Is a statement of the status quo, one of no difference or no effect.</li>
<li>If the null hypothesis is not rejected, no changes will be made.</li>
<li>Refers to a specified value of the population parameter (e.g., μ), not a sample statistic, (e.g., <span class="math inline">\(\large\overline{x}\)</span>)</li>
<li>The null hypothesis may be rejected, but it can never be accepted based on a single test. In classical hypothesis testing, there is no way to determine whether the null hypothesis is true.</li>
</ul>
<p><b>Alternative Hypothesis (H<sub>1</sub>):</b></p>
<ul>
<li>Expects some difference or effect.</li>
<li>Accepting the alternative hypothesis will lead to changes in opinions or actions.<br />
</li>
<li>Rejection of null hypothesis is taken as support for the experimental / alternative hypothesis.</li>
</ul>
<p>Furthermore, we can differentiate between directional and non-directional hypotheses:</p>
<p><b>Directional hypothesis:</b></p>
<ul>
<li>States the direction of the effect.</li>
<li>Leads to a <b>one-tailed test</b>:</li>
</ul>
<p style="text-align:center;">
<span class="math inline">\(H_0: \mu_1 \le \mu_2\)</span> <br> <span class="math inline">\(H_1: \mu_1 &gt; \mu_2\)</span>
</p>
<p>Example: the mean sales of albums sold at 7.95€ are higher than the mean sales of albums sold at 9.95€.</p>
<p><b>Non-directional hypothesis:</b></p>
<ul>
<li>States that an effect will occur, but it does not state the direction of the effect.</li>
<li>Leads to a <b>two-tailed test</b>:</li>
</ul>
<p style="text-align:center;">
<span class="math inline">\(H_0: \mu_1 = \mu_2\)</span> <br> <span class="math inline">\(H_1: \mu_1 \neq \mu_2\)</span>
</p>
<p>Example: there is no difference between the mean sales for the two different download prices.</p>
<p>In our example, a non-directional hypothesis would be appropriate. The reason is that we cannot be 100% certain about the direction that the effect might take. For example, although it might seem plausible that lower prices might lead to higher sales, it is also possible that price is perceived as a quality signal, making a product less attractive for certain consumer segments.</p>
<p style="border:3px; border-style:solid; border-color:#808080; padding: 1em;">
⚡ Rejecting the null hypothesis does not prove the alternative hypothesis (we can merely provide support for it). Rather, think of it as the chance of obtaining the data we’ve collected assuming that the null hypothesis is true.
</p>
</div>
<div id="select-an-appropriate-test" class="section level4">
<h4><span class="header-section-number">5.2.1.2</span> Select an appropriate test</h4>
<p>We fit a statistical model to the data in order to make predictions about the real world phenomenon. The test statistic measures how close the sample is to the null hypothesis. The test statistic often follows a well-known distribution (e.g., normal, t, or chi-square). To select the correct test, various factors need to be taken into consideration. Some examples are:</p>
<ul>
<li>On what scale are your variables measured (categorical vs. continuous)?</li>
<li>Do you want to test for relationships or differences?</li>
<li>If you test for differences, how many groups would you like to test?</li>
<li>For parametric tests, are the assumptions fulfilled?</li>
</ul>
<p>The following flow chart provides a rough guideline on selecting the correct test:</p>
<div class="figure">
<img src="https://github.com/IMSMWU/Teaching/raw/master/MRDA2017/testselection.JPG" alt="Flowchart for selecting an appropriate test (source: McElreath, R. (2016): Statistical Rethinking, p. 2)" />
<p class="caption">Flowchart for selecting an appropriate test (source: McElreath, R. (2016): Statistical Rethinking, p. 2)</p>
</div>
<p>For a detailed overview of the different type of tests, please also refer to <a href="https://stats.idre.ucla.edu/other/mult-pkg/whatstat/" target="_blank">this overview</a> by the UCLA.</p>
<p>In the present example, the t-test is appropriate since we would like to test for differences between two means of a single continuous variable (sales).</p>
<p>Properties of the t-distribution:</p>
<ul>
<li>Adequate when the mean for a normally distributed variable is estimated (Student’s t-distribution).</li>
<li>Assumes that the mean is known and that the population variance is estimated from a normally distributed sample.</li>
<li>The t-distribution is similar to the normal distribution in appearance (bell-shaped and symmetric).</li>
<li>As the number of degrees of freedom increases, the t-distribution approaches the normal distribution.</li>
</ul>
<p>To see this, the following graph shows the t-distribution with different degrees of freedom for a two-tailed test and α = 0.05.</p>
<p><br></p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-170"></span>
<img src="_main_files/figure-html/unnamed-chunk-170-1.png" alt="Critical values for t-distribution (two-tailed, alpha=0.05)" width="768" />
<p class="caption">
Figure 5.3: Critical values for t-distribution (two-tailed, alpha=0.05)
</p>
</div>
<p><br></p>
<p>You can see that the critical value (T<sub>CR</sub>) decreases as the degrees of freedom increase. This is due to the fact that larger degrees of freedom mean that you have more information available relative to the number of parameters that you would like to estimate.</p>
<p>Connected to the decision on how to phrase the hypotheses (directional vs. non-directional) is the choice of a one-tailed versus a two-tailed test. Let’s first think about the meaning of a one-tailed test. Using a significance level of 0.05, a one-tailed test means that 5% of the total area under the probability distribution of our test statistic is located in one tail. Thus, under a one-tailed test, we test for the possibility of the relationship in one direction only, disregarding the possibility of a relationship in the other direction. In our example, a one-tailed test will test either if the mean sales level in the experimental condition is significantly larger or smaller compared to the control condition, but not both. Depending on the direction, the mean sales level of the experimental group is significantly larger (smaller) if the test statistic is located in the top (bottom) 5% of its probability distribution, resulting in a p-value smaller than 0.05.</p>
<p>The following graph shows the critical values that our test statistic would need to surpass so that the mean difference between the groups would be deemed statistically significant. It can be seen that under a one-sided test, the rejection region is at one end of the distribution or the other. In a two-sided test, the rejection region is split between the two tails. As a consequence, the critical value of the test statistic is smaller using a one-tailed test, meaning that it has more power to detect an effect.</p>
<p><br></p>
<div class="figure" style="text-align: center"><span id="fig:fig2"></span>
<img src="_main_files/figure-html/fig2-1.png" alt="One-sided versus two-sided test (df=100, alpha=0.05)" width="960" />
<p class="caption">
Figure 5.4: One-sided versus two-sided test (df=100, alpha=0.05)
</p>
</div>
<p><br></p>
<p>In our example, we used a non-directional hypothesis, meaning that a two-sided test is appropriate. Nevertheless, let’s consider the consequences of using a directional hypothesis (one-sided test). If we assume a positive effect of price promotion on sales (reducing the price leads to higher sales), then we would expect the mean sales in the experimental group to be larger compared to the control group and, thus, derive a positive test statistic. Imagine a scenario where we need a test statistic bigger than 1.66 to find a significant effect at the 5% level under a directional hypothesis, but the test-statistic we get is actually -2.1. In this case, we would retain the null hypothesis although an effect exists and could have been detected using a two-sided test. So unless you consider the consequences of missing an effect in the untested direction negligible, you should use a two-sided test (non-directional hypothesis).</p>
<p>Now we need to make a decision between the independent and the dependent t-test. As stated above, the independent-means t-test is used when there are two experimental conditions and different units were assigned to each condition, while the dependent-means t-test is used when there are two experimental conditions and the same units were observed in both conditions of the experiment. In our example, the <b>independent-means t-test</b> is appropriate since different music albums were randomly assigned to both experimental conditions.</p>
<p>Finally, let’s test if the assumptions of the chosen test are fulfilled:</p>
<ul>
<li>A normally distributed sampling distribution (✔ - we can assume this since n &gt; 30 per group)</li>
<li>Interval or ratio data (✔ - sales is on a ratio scale)</li>
<li>Scores in different conditions are independent (✔ - products were randomly assigned)</li>
<li>Homogeneity of variance: you don’t have to worry about this assumption too much for three reasons: 1) violating this assumption only really matters if you have unequal group sizes - in our context, we have equal group sizes (n = 51 per group); 2) even if this assumption is violated, there is an adjustment (called Welch’s t-test) which corrects for unequal variances and this is easily implemented in R (actually, it is the default setting); 3) the tests for homogeneity of variances tend to work better when group sizes are equal and samples are large (which is when we don’t need it), and not so well with unequal group sizes and smaller samples (which is when you actually need it).</li>
</ul>
</div>
<div id="choose-the-level-of-significance" class="section level4">
<h4><span class="header-section-number">5.2.1.3</span> Choose the level of significance</h4>
<p>Next, we need to choose the level of significance (α). It is important to note that the choice of the significance level affects the type 1 and type 2 error:</p>
<ul>
<li>Type I error: When we believe there is a genuine effect in our population, when in fact there isn’t. Probability of type I error (α) = level of significance.</li>
<li>Type II error: When we believe that there is no effect in the population, when in fact there is.</li>
</ul>
<p>This following table shows the possible outcomes of a test (retain vs. reject H<sub>0</sub>), depending on whether H<sub>0</sub> is true or false in reality.</p>
<p><br></p>
<table style="width:100%;">
<colgroup>
<col width="17%" />
<col width="41%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th> </th>
<th>Retain <b>H<sub>0</sub></b></th>
<th>Reject <b>H<sub>0</sub></b></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><b>H<sub>0</sub> is true</b></td>
<td>Correct decision:<br>1-α (probability of correct retention);</td>
<td>Type 1 error:<br> α (level of significance)</td>
</tr>
<tr class="even">
<td><b>H<sub>0</sub> is false</b></td>
<td>Type 2 error:<br>β (type 2 error rate)</td>
<td>Correct decision:<br>1-β (power of the test)</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>When you plan to conduct an experiment, there are some factors that are under direct control of the researcher:</p>
<ul>
<li><b>Significance level (α)</b>: The probability of finding an effect that does not genuinely exist.</li>
<li><b>Sample size (n)</b>: The number of observations in each group of the experimental design.</li>
</ul>
<p>Unlike α and n, which are specified by the researcher, the magnitude of β depends on the actual value of the population parameter. In addition, β is influenced by the effect size (e.g., Cohen’s d), which can be used to determine a standardized measure of the magnitude of an observed effect. The following parameters are affected more indirectly:</p>
<ul>
<li><b>Power (1-β)</b>: The probability of finding an effect that does genuinely exists.</li>
<li><b>Effect size (d)</b>: Standardized measure of the effect size under the alternate hypothesis.</li>
</ul>
<p>Although β is unknown, it is related to α. For example, if we would like to be absolutely sure that we do not falsely identify an effect which does not exist (i.e., make a type I error), this means that the probability of identifying an effect that does exist (i.e., 1-β) decreases and vice versa. Thus, an extremely low value of α (e.g., α = 0.0001) will result in intolerably high β errors. A common approach is to set α=0.05 and β=0.80.</p>
<p>Unlike the t-value of our test, the effect size (d) is unaffected by the sample size and can be categorized as follows (see Cohen, J. 1988):</p>
<ul>
<li>0.2 (small effect)</li>
<li>0.5 (medium effect)</li>
<li>0.8 (large effect)</li>
</ul>
<p>In order to test more subtle effects (smaller effect sizes), you need a larger sample size compared to the test of more obvious effects. In <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2205186" target="_blank">this paper</a>, you can find a list of examples for different effect sizes and the number of observations you need to reliably find an effect of that magnitude. Although the exact effect size is unknown before the experiment, you might be able to make a guess about the effect size (e.g., based on previous studies).</p>
<p>When constructing an experimental design, your goal should be to maximize the power of the test while maintaining an acceptable significance level and keeping the sample as small as possible. To achieve this goal, you may use the <code>pwr</code> package, which let’s you compute <code>n</code>, <code>d</code>, <code>alpha</code>, and <code>power</code>. You only need to specify three of the four input variables to get the fourth.</p>
<p>For example, what sample size do we need (per group) to identify an effect with d = 0.6, α = 0.05, and power = 0.8:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(pwr)
<span class="kw">pwr.t.test</span>(<span class="dt">d =</span> <span class="fl">0.6</span>, <span class="dt">sig.level =</span> <span class="fl">0.05</span>, <span class="dt">power =</span> <span class="fl">0.8</span>, 
    <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;two.sample&quot;</span>), <span class="dt">alternative =</span> <span class="kw">c</span>(<span class="st">&quot;two.sided&quot;</span>))</code></pre></div>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 44.58577
##               d = 0.6
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>Or we could ask, what is the power of our test with 51 observations in each group, d = 0.6, and α = 0.05:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pwr.t.test</span>(<span class="dt">n =</span> <span class="dv">51</span>, <span class="dt">d =</span> <span class="fl">0.6</span>, <span class="dt">sig.level =</span> <span class="fl">0.05</span>, <span class="dt">type =</span> <span class="kw">c</span>(<span class="st">&quot;two.sample&quot;</span>), 
    <span class="dt">alternative =</span> <span class="kw">c</span>(<span class="st">&quot;two.sided&quot;</span>))</code></pre></div>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 51
##               d = 0.6
##       sig.level = 0.05
##           power = 0.850985
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
</div>
<div id="collect-data-and-calculate-the-test-statistic" class="section level4">
<h4><span class="header-section-number">5.2.1.4</span> Collect data and calculate the test statistic</h4>
<div id="step-1-compute-means-and-variances-of-samples" class="section level5 unnumbered">
<h5>Step 1: Compute means and variances of samples</h5>
<p>The two populations are sampled and the means and variances are computed based on samples of sizes n1 and n2.</p>
Mean of sample 1:
<span class="math display" id="eq:meansample1">\[\begin{equation} 
\begin{split}
\overline{X}_1=\frac{\sum_{i=1}^{n_1} X_i}{n_1} = \frac{427}{51} = 8.37
\end{split}
\tag{5.3}
\end{equation}\]</span>
Variance of sample 1:
<span class="math display" id="eq:variancesample1">\[\begin{equation} 
\begin{split}
s_1=\frac{\sum_{i=1}^{n_1} (X_i-\overline{X}_1)^2}{n_1-1}=41.52
\end{split}
\tag{5.4}
\end{equation}\]</span>
Mean of sample 2:
<span class="math display" id="eq:meansample2">\[\begin{equation} 
\begin{split}
\overline{X}_2=\frac{\sum_{i=1}^{n_2} X_i}{n_2} = \frac{564}{12} = 5.86
\end{split}
\tag{5.5}
\end{equation}\]</span>
Variance of sample 2:
<span class="math display" id="eq:variancesample2">\[\begin{equation} 
\begin{split}
s_2=\frac{\sum_{i=1}^{n_2} (X_i-\overline{X}_2)^2}{n_2-1}=34.48
\end{split}
\tag{5.6}
\end{equation}\]</span>
<p><br> Let’s test if the calculated values are correct:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mean_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">mean</span>(music_sales[music_sales<span class="op">$</span>group <span class="op">==</span><span class="st"> &quot;low_price&quot;</span>, 
    <span class="st">&quot;unit_sales&quot;</span>])
mean_<span class="dv">1</span></code></pre></div>
<pre><code>## [1] 8.372549</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">var</span>(music_sales[music_sales<span class="op">$</span>group <span class="op">==</span><span class="st"> &quot;low_price&quot;</span>, 
    <span class="st">&quot;unit_sales&quot;</span>])
var_<span class="dv">1</span></code></pre></div>
<pre><code>## [1] 41.51843</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mean_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">mean</span>(music_sales[music_sales<span class="op">$</span>group <span class="op">==</span><span class="st"> &quot;high_price&quot;</span>, 
    <span class="st">&quot;unit_sales&quot;</span>])
mean_<span class="dv">2</span></code></pre></div>
<pre><code>## [1] 5.862745</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">var</span>(music_sales[music_sales<span class="op">$</span>group <span class="op">==</span><span class="st"> &quot;high_price&quot;</span>, 
    <span class="st">&quot;unit_sales&quot;</span>])
var_<span class="dv">2</span></code></pre></div>
<pre><code>## [1] 34.48078</code></pre>
</div>
<div id="step-2-compute-pooled-variance-estimate-from-the-sample-variances" class="section level5 unnumbered">
<h5>Step 2: Compute pooled variance estimate from the sample variances</h5>
<p>When we compare two groups that contain different numbers of participants and the populations can be expected to have approximately the same variances, we apply a weighting of the variances of each sample to compute the <b>pooled variance</b>.</p>
<span class="math display" id="eq:pooledvariance">\[\begin{equation} 
\begin{split}
s_p=\frac{\sum_{i=1}^{n_1}(X_i-\overline{X}_1)^2+\sum_{i=1}^{n_2}(X_i-\overline{X}_2)^2}{n_1+n_2-2}=\frac{(n_1-1)*s_1^2+(n_2-1)*s_2^2}{n_1+n_2-2}=37.99
\end{split}
\tag{5.7}
\end{equation}\]</span>
<p><br> Let’s test if the calculated value is correct:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">nrow</span>(music_sales[music_sales<span class="op">$</span>group <span class="op">==</span><span class="st"> &quot;low_price&quot;</span>, 
    ])
n_<span class="dv">1</span></code></pre></div>
<pre><code>## [1] 51</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">nrow</span>(music_sales[music_sales<span class="op">$</span>group <span class="op">==</span><span class="st"> &quot;high_price&quot;</span>, 
    ])
n_<span class="dv">2</span></code></pre></div>
<pre><code>## [1] 51</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_pooled &lt;-<span class="st"> </span>((n_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>var_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(n_<span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>var_<span class="dv">2</span>)<span class="op">/</span>(n_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>n_<span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span>)
var_pooled</code></pre></div>
<pre><code>## [1] 37.99961</code></pre>
<p>Note that in this case, both groups contain the same number of observations. Therefore, the weighting is not really needed. The weighting is only necessary to account for differences in sample size between groups. In our case, the following would yield the same result because the sample sizes are the same.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">var_non_pooled &lt;-<span class="st"> </span>(var_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>var_<span class="dv">2</span>)<span class="op">/</span><span class="dv">2</span>
var_non_pooled</code></pre></div>
<pre><code>## [1] 37.99961</code></pre>
</div>
<div id="step-3-compute-the-standard-error-of-the-differences" class="section level5 unnumbered">
<h5>Step 3: Compute the standard error of the differences</h5>
<p>According to the variance sum law, to find the variance of the sampling distribution of differences, we merely need to add together the variances of the sampling distributions of the two populations that we are comparing:</p>
<span class="math display" id="eq:addvariances">\[\begin{equation} 
\begin{split}
s_{\overline{X}_1-\overline{X}_2}^2={\frac{s_1^2}{N_1}+\frac{s_2^2}{N_2}}
\end{split}
\tag{5.8}
\end{equation}\]</span>
<p>Now we have the variance of the sampling distribution of differences. To find the standard error, we only need to take the square root of the variance (because the standard error is the standard deviation of the sampling distribution and the standard error is the square root of the variance):</p>
<span class="math display" id="eq:addvariances2">\[\begin{equation} 
\begin{split}
s_{\overline{X}_1-\overline{X}_2}=\sqrt{{\frac{s_1^2}{N_1}+\frac{s_2^2}{N_2}}}=\sqrt{{\frac{37.99}{51}+\frac{37.99}{51}}}=1.22
\end{split}
\tag{5.9}
\end{equation}\]</span>
<p><br></p>
<p>Let’s check again if the result is correct:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">se_x1_x2 &lt;-<span class="st"> </span><span class="kw">sqrt</span>((var_pooled<span class="op">/</span>n_<span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>(var_pooled<span class="op">/</span>n_<span class="dv">2</span>))
se_x1_x2</code></pre></div>
<pre><code>## [1] 1.22073</code></pre>
</div>
<div id="step-4-compute-the-value-of-the-test-statistic" class="section level5 unnumbered">
<h5>Step 4: Compute the value of the test statistic</h5>
<p>The test statistic can now be calculated as: <br></p>
<span class="math display" id="eq:tstat">\[\begin{equation} 
\begin{split}
t=\frac{(\overline{X}_1-\overline{X}_2)-(\mu_1-\mu_2)}{\sqrt{{\frac{s_1^2}{N_1}+\frac{s_2^2}{N_2}}}}=\frac{(8.37-5.86)-0}{1.22}=2.06
\end{split}
\tag{5.10}
\end{equation}\]</span>
<p><br></p>
<p>Note that <span class="math inline">\((\mu_1-\mu_2)=0\)</span>, because <span class="math inline">\(H_0: \mu_1=\mu_2\)</span></p>
<p><br> And again, we check the result:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t_cal &lt;-<span class="st"> </span>(mean_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_<span class="dv">2</span>)<span class="op">/</span>se_x1_x2
t_cal</code></pre></div>
<pre><code>## [1] 2.055987</code></pre>
<p>Note that you don’t have to compute these statistics manually! Luckily, there is a function for the t-test, which computes steps 1-4 for you in just one single line of code:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(unit_sales <span class="op">~</span><span class="st"> </span>group, <span class="dt">data =</span> music_sales)</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  unit_sales by group
## t = 2.056, df = 99.15, p-value = 0.04241
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.08765687 4.93195097
## sample estimates:
##  mean in group low_price mean in group high_price 
##                 8.372549                 5.862745</code></pre>
<p>Note that the degrees of freedom are not 100 (as we would expect), but 99.15 instead. This difference is because of the Welch correction, which adjusts the degrees of freedom based on the homogeneity of variance. R implements this correction by default and it is okay for you to report the adjusted results. However, you could also force R to assume equal variances to exactly replicate the results we derived through manual calculations using the <code>var.equal=TRUE</code> argument. In this case you would first need to test if this assumption is fulfilled using Levene’s Test, which tests H<sub>0</sub> = group variances are equal; H<sub>1</sub> = group variances are not equal (the <code>leveneTest(...)</code> function is in the <code>car</code> package).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)
<span class="kw">leveneTest</span>(unit_sales <span class="op">~</span><span class="st"> </span>group, <span class="dt">data =</span> music_sales)</code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##        Df F value Pr(&gt;F)
## group   1  0.0085 0.9269
##       100</code></pre>
<p>In this case, we fail to reject the Null of equal variances (p &gt; 0.05), hence the variances are equal (however, see above regarding the concerns about this test). Now we run the t-test using the <code>var.equal=TRUE</code> argument:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(unit_sales <span class="op">~</span><span class="st"> </span>group, <span class="dt">data =</span> music_sales, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  unit_sales by group
## t = 2.056, df = 100, p-value = 0.04239
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.08791121 4.93169663
## sample estimates:
##  mean in group low_price mean in group high_price 
##                 8.372549                 5.862745</code></pre>
<p>As you can see, the results are fairly similar and it is fine to rely solely on the corrected results (i.e., Welch’s t-test).</p>
</div>
<div id="effect-size" class="section level5 unnumbered">
<h5>Effect size</h5>
<p>If you wish to obtain a standardized measure of the effect, you may compute the effect size (Cohen’s d) as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d &lt;-<span class="st"> </span>(mean_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_<span class="dv">2</span>)<span class="op">/</span><span class="kw">sqrt</span>(var_pooled <span class="op">+</span><span class="st"> </span>var_pooled<span class="op">/</span><span class="dv">2</span>)
d</code></pre></div>
<pre><code>## [1] 0.3324334</code></pre>
<p>According to the thresholds defined above, this effect would be judged to be a small-medium effect.</p>
</div>
</div>
<div id="reject-or-do-not-reject-h0" class="section level4">
<h4><span class="header-section-number">5.2.1.5</span> Reject or do not reject H<sub>0</sub></h4>
<p>There are different (albeit interrelated) ways of deciding whether a hypothesis should be rejected:</p>
<div id="p-value" class="section level5">
<h5><span class="header-section-number">5.2.1.5.1</span> p-value</h5>
<ul>
<li>Determine the probability associated with the test statistic TS<sub>CAL</sub> (p-value).</li>
<li>Compare the p-value with the level of significance, α.</li>
<li>The p-value is the likelihood of observing a result when the null hypothesis is true (probability of obtaining a particular value).</li>
<li>A small p-value signals that it is unlikely to observe TS<sub>CAL</sub> under the null hypothesis.</li>
<li>You reject H<sub>0</sub> if the p-value is smaller than α.</li>
</ul>
<p>The p-value is included in the output from the t-test above. However, you can calculate the p-value for T<sub>CAL</sub> manually as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span>(n_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>n_<span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span>)
<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pt</span>(<span class="kw">abs</span>(t_cal), df))</code></pre></div>
<pre><code>## [1] 0.04238901</code></pre>
<p>Here, <code>pt()</code> is the cumulative probability distribution function of the t-distribution. Cumulative probability means that the function returns the probability that the test statistic will take a value <strong>less than or equal to</strong> the calculated test statistic given the the degrees of freedom. However, we are interested in obtaining the probability of observing a test statistic <strong>larger than or equal to</strong> the calculated test statistic under the null hypothesis (i.e., the p-value). Thus, we need to subtract the cumulative probability from 1. In addition, since we are running a two-sided test, we need to multiply the probability by 2 to account for the rejection region at the other side of the distribution.</p>
<p><strong>Interpretation:</strong> Under the assumption that the null hypothesis is true the probability of finding a difference of at least the observed magnitude is less than 5%.</p>
<p><strong>Decision:</strong> Reject H<sub>0</sub>, given that the p-value of 0.042 is smaller than 0.05.</p>
<p>However, remember that the p-value does not tell us anything about the likelihood of the alternative hypothesis!</p>
</div>
<div id="t-value" class="section level5">
<h5><span class="header-section-number">5.2.1.5.2</span> t-value</h5>
<ul>
<li>Determine the critical value of the test statistic (TS<sub>CR</sub>) in order to define the rejection region and the non-rejection region.</li>
<li>Determine if TS<sub>CAL</sub> falls into rejection or non-rejection region.</li>
<li>If the (absolute) calculated value of the test statistic (T<sub>CAL</sub>) is greater than the (absolute) critical value of the test statistic (T<sub>CR</sub>), H<sub>0</sub> is rejected.</li>
<li>If the (absolute) calculated value of the test statistic (T<sub>CAL</sub>) is larger than the (absolute) critical value of the test statistic (T<sub>CR</sub>) , the null hypothesis can not be rejected.</li>
</ul>
<p>However, remember that this does not mean that the null hypothesis is true!</p>
<p>The calculated test statistic is included in the output from the t-test above. In order to determine if the calculated test statistic is larger than the critical value, you can refer to the probability table of the t-distribution to look up the critical value for the given degrees of freedom. However, you can also test if the calculated test statistic is larger than the critical value manually using the <code>qt()</code>-function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span>(n_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>n_<span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span>)
t_cal <span class="op">&gt;</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, df)</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>We use <code>0.975</code> and not <code>0.95</code> since we are running a two-sided test and need to account for the rejection region at the other end of the distribution. The output suggests that the calculated t-value is larger than the critical value for the given level of α.</p>
<p><b>Interpretation:</b> The probability of observing a difference in means of this magnitude or larger is less than 5%.</p>
<p><b>Decision:</b> Reject H<sub>0</sub>, given that the calculated t-value (T<sub>CAL</sub>) of 2.0559868 is larger than critical value (T<sub>CR</sub>) of 1.9839715.</p>
<p>The following graph shows the test result.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-184"></span>
<img src="_main_files/figure-html/unnamed-chunk-184-1.png" alt="Visual depiction of the test result" width="672" />
<p class="caption">
Figure 5.5: Visual depiction of the test result
</p>
</div>
<p>You can see that the calculated test-statistic (red line) falls into the rejection region.</p>
</div>
<div id="confidence-interval" class="section level5">
<h5><span class="header-section-number">5.2.1.5.3</span> Confidence interval</h5>
<p>For a given statistic calculated for a sample of observations (e.g., difference in means), the confidence interval is a range around that statistic that is believed to contain, with a certain probability (e.g., 95%), the true value of that statistic under (hypothetical) repeated sampling. In our example, the 95% confidence interval is constructed such that in 95% of samples, the true value of the population mean difference will fall within its limits.</p>
<p>The computation of the 95% confidence interval for the t-test is:</p>
<span class="math display" id="eq:confidence">\[\begin{equation} 
\begin{split}
CI = (\overline{X}_1-\overline{X}_2)\pm t_{1-\frac{\alpha}{2}}*\sqrt{{\frac{s_p^2}{N_1}+\frac{s_p^2}{N_2}}}
\end{split}
\tag{5.11}
\end{equation}\]</span>
<p>Luckily, the interval is already given in the output of the t-test above. However, we can also compute the interval manually:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(mean_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_<span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, df) <span class="op">*</span><span class="st"> </span>se_x1_x2</code></pre></div>
<pre><code>## [1] 0.08791121</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(mean_<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>mean_<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, df) <span class="op">*</span><span class="st"> </span>se_x1_x2</code></pre></div>
<pre><code>## [1] 4.931697</code></pre>
<p>If the parameter value specified in the null hypothesis (usually 0) does not lie within the bounds, we reject H<sub>0</sub>.</p>
<p><b>Interpretation:</b> With a 95% probability the mean difference between the populations will lie within [0.09; 4.93].</p>
<p><b>Decision:</b> Reject H<sub>0</sub>, given that the true parameter (zero) is not included in the interval.</p>
<p>To illustrate this, we can randomly draw 100 samples from the two populations using simulated data, compute their means and construct confidence intervals around their mean difference. The result is shown in the following graph:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-186"></span>
<img src="_main_files/figure-html/unnamed-chunk-186-1.png" alt="Confidence Intervals" width="576" />
<p class="caption">
Figure 5.6: Confidence Intervals
</p>
</div>
<p>You can see that for 5 out of 100 samples, the calculated confidence interval does not contain the true population mean (red line).</p>
</div>
</div>
<div id="report-results-and-draw-a-marketing-conclusion" class="section level4">
<h4><span class="header-section-number">5.2.1.6</span> Report results and draw a marketing conclusion</h4>
<p>The conclusion reached by hypothesis testing must finally be expressed in terms of the marketing research problem:</p>
<p>The test showed that the sales promotion increased sales by about 2.51 unit on average. This difference is significant t(100) = 2.056, p &lt; .05 (95% CI = [0.09,4.93]).</p>
<p><strong>The following video summarizes how to conduct an independent-means t-test in R</strong></p>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/KegcCmR3krY" frameborder="0" allowfullscreen>
</iframe>
</div>
</div>
<div id="a-note-on-the-interpretation-of-p-values" class="section level4">
<h4><span class="header-section-number">5.2.1.7</span> A note on the interpretation of p-values</h4>
<p>From my experience, students tend to place a lot of weight on p-values when interpreting their research findings. It is therefore important to note some points that hopefully help to put the meaning of a “significant” vs. “insignificant” test result into perspective.</p>
<p><b>Significant result</b></p>
<ul>
<li>Even if the probability of the effect being a chance result is small (e.g., less than .05) it doesn’t necessarily mean that the effect is important.</li>
<li>Very small and unimportant effects can turn out to be statistically significant if the sample size is large enough.</li>
</ul>
<p><b>Insignificant result</b></p>
<ul>
<li>If the probability of the effect occurring by chance is large (greater than .05), the alternative hypothesis is rejected. However, this does not mean that the null hypothesis is true.</li>
<li>Although an effect might not be large enough to be anything other than a chance finding, it doesn’t mean that the effect is zero.</li>
<li>In fact, two random samples will always have slightly different means that would deemed to be statistically significant if the samples were large enough.</li>
</ul>
<p>Thus, you should not base your research conclusion on p-values alone!</p>
<p>It is also crucial to <strong>determine the sample size before you run the experiment</strong> or before you start your analysis. Why? Consider the following example:</p>
<ul>
<li>You run an experiment</li>
<li>After each respondent you analyze the data and look at the mean difference between the two groups with a t-test</li>
<li>You stop when you have a significant effect</li>
</ul>
<p>This is called p-hacking and should be avoided at all costs. Assuming that both groups come from the same population (i.e., there is <strong>no difference</strong> in the means): What is the likelihood that the result will be significant at some point? In other words, what is the likelihood that you will draw the wrong conclusion from your data that there is an effect, while there is none? This is shown in the following graph using simulated data - the color red indicates significant test results that arise although there is no effect (i.e., false positives).</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-187"></span>
<img src="_main_files/figure-html/unnamed-chunk-187-1.png" alt="p-hacking (red indicates false positives)" width="672" />
<p class="caption">
Figure 5.7: p-hacking (red indicates false positives)
</p>
</div>
</div>
</div>
<div id="dependent-means-t-test" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Dependent-means t-test</h3>
<p>While the independent-means t-test is used when different units (e.g., participants, products) were assigned to the different condition, the <b>dependent-means t-test</b> is used when there are two experimental conditions and the same units (e.g., participants, products) were observed in both experimental conditions.</p>
<p>Imagine, for example, a slightly different experimental setup for the price experiment:</p>
<p><strong>Example case:</strong> What is the effect of personalized, dynamic pricing on the sales of music albums?</p>
<p><strong>Experimental setup:</strong> In a music download store, new releases were either sold at a reduced price (i.e., 7.95€), or at the standard price (9.95€). Every time a customer came to the store, the prices were randomly determined for every new release. This means that the same 51 albums were either sold at the standard price or at the reduced price and this price was determined randomly. The sales were then recorded over one day. Note the difference to the previous case, where we randomly split the sample and assigned 50% of products to each condition. Now, we randomly vary prices for all albums between high and low prices.</p>
<p>Let’s load and inspect the data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rm</span>(music_sales_dep)
music_sales_dep &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/music_experiment_dependent.dat&quot;</span>, 
    <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)  <span class="co">#read in data</span>
<span class="kw">str</span>(music_sales_dep)  <span class="co">#inspect data</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    51 obs. of  3 variables:
##  $ product_id           : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ unit_sales_low_price : int  6 27 30 24 21 11 18 15 18 13 ...
##  $ unit_sales_high_price: int  9 12 30 18 20 15 2 3 3 9 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(music_sales_dep)  <span class="co">#inspect data</span></code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["product_id"],"name":[1],"type":["int"],"align":["right"]},{"label":["unit_sales_low_price"],"name":[2],"type":["int"],"align":["right"]},{"label":["unit_sales_high_price"],"name":[3],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"6","3":"9"},{"1":"2","2":"27","3":"12"},{"1":"3","2":"30","3":"30"},{"1":"4","2":"24","3":"18"},{"1":"5","2":"21","3":"20"},{"1":"6","2":"11","3":"15"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The data are actually the same as before, only now we assume that the observations at different price points come from the same users.</p>
<p>Since we are working with the same data (in a different format), the descriptives are the same as before:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(music_sales_dep[, <span class="kw">c</span>(<span class="st">&quot;unit_sales_low_price&quot;</span>)])  <span class="co">#frequencies low price</span></code></pre></div>
<pre><code>## 
##  2  3  4  5  6  9 10 11 12 13 15 18 21 24 27 30 
##  2  8  4  2 18  3  1  1  3  1  2  2  1  1  1  1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(music_sales_dep[, <span class="kw">c</span>(<span class="st">&quot;unit_sales_high_price&quot;</span>)])  <span class="co">#frequencies high price</span></code></pre></div>
<pre><code>## 
##  0  1  2  3  6  9 12 15 18 20 30 
##  7  1  4 16  9  6  3  2  1  1  1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">psych<span class="op">::</span><span class="kw">describe</span>(music_sales_dep[, <span class="kw">c</span>(<span class="st">&quot;unit_sales_low_price&quot;</span>, 
    <span class="st">&quot;unit_sales_high_price&quot;</span>)])  <span class="co">#overall descriptives</span></code></pre></div>
<pre><code>##                       vars  n mean   sd median trimmed  mad min max range
## unit_sales_low_price     1 51 8.37 6.44      6    7.17 4.45   2  30    28
## unit_sales_high_price    2 51 5.86 5.87      3    4.90 4.45   0  30    30
##                       skew kurtosis   se
## unit_sales_low_price  1.66     2.22 0.90
## unit_sales_high_price 1.84     4.10 0.82</code></pre>
<p>To plot the data, we need to do some restructuring first, since the variables are now stored in two different columns (“unit_sales_low_price” and “unit_sales_high_price”). This is also known as the “wide” format. To plot the data we need all observations to be stored in one variable. This is also known as the “long” format. We can use the <code>melt(...)</code> function from the <code>reshape2</code>package to “melt” the two variable into one column to plot the data. Since we are working with the same data as before, the plot is the same as before.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(reshape2)
<span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">melt</span>(music_sales_dep[, <span class="kw">c</span>(<span class="st">&quot;unit_sales_low_price&quot;</span>, 
    <span class="st">&quot;unit_sales_high_price&quot;</span>)]), <span class="kw">aes</span>(<span class="dt">x =</span> variable, <span class="dt">y =</span> value)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">geom_bar</span>(<span class="dt">stat =</span> <span class="st">&quot;summary&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>, 
        <span class="dt">width =</span> <span class="fl">0.7</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_pointrange</span>(<span class="dt">stat =</span> <span class="st">&quot;summary&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Group&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Average number of sales&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-190"></span>
<img src="_main_files/figure-html/unnamed-chunk-190-1.png" alt="plot of means (dependent test)" width="672" />
<p class="caption">
Figure 5.8: plot of means (dependent test)
</p>
</div>
<p>Suppose we want to test the hypothesis that there is no difference in means between the two groups.</p>
<p style="text-align:center;">
<span class="math inline">\(H_0: \mu_D = 0\)</span> <br> <span class="math inline">\(H_1: \mu_D \neq 0\)</span>
</p>
<p>Where <code>D</code> denotes the difference between the observations from the two price groups. Let’s compute a new variable which is the difference between the price groups. H<sub>0</sub> states that this difference should be 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">music_sales_dep<span class="op">$</span>difference &lt;-<span class="st"> </span>music_sales_dep<span class="op">$</span>unit_sales_low_price <span class="op">-</span><span class="st"> </span>
<span class="st">    </span>music_sales_dep<span class="op">$</span>unit_sales_high_price
music_sales_dep</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["product_id"],"name":[1],"type":["int"],"align":["right"]},{"label":["unit_sales_low_price"],"name":[2],"type":["int"],"align":["right"]},{"label":["unit_sales_high_price"],"name":[3],"type":["int"],"align":["right"]},{"label":["difference"],"name":[4],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"6","3":"9","4":"-3"},{"1":"2","2":"27","3":"12","4":"15"},{"1":"3","2":"30","3":"30","4":"0"},{"1":"4","2":"24","3":"18","4":"6"},{"1":"5","2":"21","3":"20","4":"1"},{"1":"6","2":"11","3":"15","4":"-4"},{"1":"7","2":"18","3":"2","4":"16"},{"1":"8","2":"15","3":"3","4":"12"},{"1":"9","2":"18","3":"3","4":"15"},{"1":"10","2":"13","3":"9","4":"4"},{"1":"11","2":"6","3":"3","4":"3"},{"1":"12","2":"6","3":"2","4":"4"},{"1":"13","2":"3","3":"12","4":"-9"},{"1":"14","2":"9","3":"1","4":"8"},{"1":"15","2":"6","3":"3","4":"3"},{"1":"16","2":"4","3":"9","4":"-5"},{"1":"17","2":"6","3":"6","4":"0"},{"1":"18","2":"9","3":"3","4":"6"},{"1":"19","2":"12","3":"6","4":"6"},{"1":"20","2":"6","3":"12","4":"-6"},{"1":"21","2":"5","3":"6","4":"-1"},{"1":"22","2":"3","3":"6","4":"-3"},{"1":"23","2":"6","3":"15","4":"-9"},{"1":"24","2":"6","3":"9","4":"-3"},{"1":"25","2":"6","3":"3","4":"3"},{"1":"26","2":"5","3":"3","4":"2"},{"1":"27","2":"3","3":"2","4":"1"},{"1":"28","2":"6","3":"9","4":"-3"},{"1":"29","2":"6","3":"0","4":"6"},{"1":"30","2":"6","3":"0","4":"6"},{"1":"31","2":"12","3":"6","4":"6"},{"1":"32","2":"6","3":"9","4":"-3"},{"1":"33","2":"6","3":"3","4":"3"},{"1":"34","2":"6","3":"3","4":"3"},{"1":"35","2":"6","3":"3","4":"3"},{"1":"36","2":"3","3":"3","4":"0"},{"1":"37","2":"4","3":"3","4":"1"},{"1":"38","2":"6","3":"0","4":"6"},{"1":"39","2":"4","3":"6","4":"-2"},{"1":"40","2":"2","3":"6","4":"-4"},{"1":"41","2":"3","3":"6","4":"-3"},{"1":"42","2":"6","3":"0","4":"6"},{"1":"43","2":"4","3":"2","4":"2"},{"1":"44","2":"3","3":"0","4":"3"},{"1":"45","2":"3","3":"0","4":"3"},{"1":"46","2":"15","3":"3","4":"12"},{"1":"47","2":"10","3":"6","4":"4"},{"1":"48","2":"9","3":"3","4":"6"},{"1":"49","2":"3","3":"0","4":"3"},{"1":"50","2":"12","3":"3","4":"9"},{"1":"51","2":"2","3":"3","4":"-1"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The mean of the paired differences is</p>
<span class="math display" id="eq:meandiff">\[\begin{equation} 
\begin{split}
\overline{D}=\frac{\sum_{i=1}^{n}D_i}{n}=\frac{128}{51}=2.510
\end{split}
\tag{5.12}
\end{equation}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mean_d &lt;-<span class="st"> </span><span class="kw">sum</span>(music_sales_dep<span class="op">$</span>difference)<span class="op">/</span><span class="kw">length</span>(music_sales_dep<span class="op">$</span>difference)
mean_d</code></pre></div>
<pre><code>## [1] 2.509804</code></pre>
<p>The standard deviation of the paired differences is</p>
<span class="math display" id="eq:sddiff">\[\begin{equation} 
\begin{split}
s_D = \sqrt\frac{\sum_{i=1}^{n}(D_i-\overline{D})^2}{n-1}=5.651
\end{split}
\tag{5.13}
\end{equation}\]</span>
<p>and the standard error of the paired differences is</p>
<span class="math display" id="eq:sediff">\[\begin{equation} 
\begin{split}
s_\overline{D} = \frac{s_D}{\sqrt{n}}=\frac{5.651}{\sqrt{51}}=0.791
\end{split}
\tag{5.14}
\end{equation}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sd_d &lt;-<span class="st"> </span><span class="kw">sd</span>(music_sales_dep<span class="op">$</span>difference)  <span class="co">#standard deviation</span>
sd_d</code></pre></div>
<pre><code>## [1] 5.651097</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n_d &lt;-<span class="st"> </span><span class="kw">nrow</span>(music_sales_dep)  <span class="co">#number of observations</span>
n_d</code></pre></div>
<pre><code>## [1] 51</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">se_d &lt;-<span class="st"> </span><span class="kw">sd</span>(music_sales_dep<span class="op">$</span>difference)<span class="op">/</span><span class="kw">sqrt</span>(n_d)  <span class="co">#standard error</span>
se_d</code></pre></div>
<pre><code>## [1] 0.7913119</code></pre>
<p>The test statistic is therefore:</p>
<span class="math display" id="eq:teststatpaired">\[\begin{equation} 
\begin{split}
t = \frac{\overline{D}-\mu_d}{s_\overline{D}}=\frac{2.510-0}{0.791}=3.172
\end{split}
\tag{5.15}
\end{equation}\]</span>
<p>on 50 (i.e., n-1) degrees of freedom</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t_cal &lt;-<span class="st"> </span>mean_d<span class="op">/</span>se_d
t_cal</code></pre></div>
<pre><code>## [1] 3.1717</code></pre>
<p>Note that although we used the same data as before, the calculated test statistic is larger compared to the independent t-test. This is because in the dependent sample test, the observations come from the same observational units (i.e., products). Hence, there is no unsystematic variation due to potential differences between products that were assigned to the experimental groups. This means that the influence of unobserved factors (unsystematic variation) relative to the variation due to the experimental manipulation (systematic variation) is not as strong in the dependent-means test compared to the independent-means test.</p>
<p>The confidence interval can be computed as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">nrow</span>(music_sales_dep) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>
(mean_d) <span class="op">-</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, df) <span class="op">*</span><span class="st"> </span>se_d</code></pre></div>
<pre><code>## [1] 0.9204072</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(mean_d) <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, df) <span class="op">*</span><span class="st"> </span>se_d</code></pre></div>
<pre><code>## [1] 4.099201</code></pre>
<p>Again, we don’t have to compute all this by hand since the <code>t.test(...)</code> function can be used to do it for us. Now we have to use the argument <code>paired=TRUE</code> to let R know that we are working with dependent observations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(music_sales_dep<span class="op">$</span>unit_sales_low_price, music_sales_dep<span class="op">$</span>unit_sales_high_price, 
    <span class="dt">paired =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  music_sales_dep$unit_sales_low_price and music_sales_dep$unit_sales_high_price
## t = 3.1717, df = 50, p-value = 0.00259
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.9204072 4.0992007
## sample estimates:
## mean of the differences 
##                2.509804</code></pre>
<p>The p-value associated with the test statistic is already reported in the output. However, we could still validate this result manually to see if the calculated test statistic is larger than the critical value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span>(n_d <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)  <span class="co">#degrees of freedom</span>
<span class="kw">qt</span>(<span class="fl">0.975</span>, df)  <span class="co">#critical value</span></code></pre></div>
<pre><code>## [1] 2.008559</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t_cal  <span class="co">#calculated value</span></code></pre></div>
<pre><code>## [1] 3.1717</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t_cal <span class="op">&gt;</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, df)  <span class="co">#check if calculated value is larger than critical</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>Finally, we need to report the results:</p>
<p>On average, the same music albums sold more units at the lower price point (M = 8.37, SE = 0.902) compared to the higher price point (M = 5.86, SE = 0.822). This difference was significant t(50) = 3.172, p &lt; .01 (95% CI = [0.920, 4.099]).</p>
<p><strong>The following video summarizes how to conduct an dependent-means t-test in R</strong></p>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/F0sGRYvgyBQ" frameborder="0" allowfullscreen>
</iframe>
</div>
</div>
<div id="one-sample-t-test" class="section level3">
<h3><span class="header-section-number">5.2.3</span> One-sample t-test</h3>
<p>If we are not interested in comparing groups, but would like to test if the mean of a variable is different from a specified threshold, we can use the one-sample t-test. Suppose we wanted to test the hypothesis that the overall mean sales in the “music_experiment.dat” exceeds 4.0 at a significance level of α = 0.05. The hypothesis would be:</p>
<p style="text-align:center;">
<span class="math inline">\(H_0: \mu \le 4.0\)</span> <br> <span class="math inline">\(H_1: \mu &gt; 4.0\)</span>
</p>
<p>The estimate of the standard error is simply the standard deviation over the square root of n:</p>
<span class="math display" id="eq:teststatunpaired">\[\begin{equation} 
\begin{split}
s_\overline{x}=\frac{s_x}{\sqrt{n}}=\frac{6.26}{\sqrt{102}}=0.62
\end{split}
\tag{5.16}
\end{equation}\]</span>
<p>and the t-value is simply</p>
<span class="math display" id="eq:tunpaired">\[\begin{equation} 
\begin{split}
t=\frac{\overline{X}-\mu}{s_\overline{x}}=\frac{7.12-4}{0.62}=5.03
\end{split}
\tag{5.17}
\end{equation}\]</span>
<p>The degrees of freedom for the t-statistic to test the hypothesis about one mean are n-1 (= 101). From the t distribution, the probability of getting a more extreme value than 5.03 is less than 0.05. Hence, H<sub>0</sub> is rejected. Alternatively, the critical t-value for 101 degrees of freedom and a significance level of 0.05 is 1.645. This implies that the average sales level exceeds 4.0.</p>
<p>This can be implemented using the <code>t.test</code> function and specifying <code>mu</code> as the threshold for your test and using the argument <code>alternative</code> to specify the direction in which we would like to test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(music_sales<span class="op">$</span>unit_sales, <span class="dt">mu =</span> <span class="dv">4</span>, <span class="dt">alternative =</span> <span class="st">&quot;greater&quot;</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  music_sales$unit_sales
## t = 5.0281, df = 101, p-value = 0.000001076
## alternative hypothesis: true mean is greater than 4
## 95 percent confidence interval:
##  6.088332      Inf
## sample estimates:
## mean of x 
##  7.117647</code></pre>
<p>Report the results:</p>
<p>On average, the sales level in our sample exceeded the value 4.0 (M = 7.12, SE = 0.620). This difference was significant t(101) = 5.028, p &lt; .05.</p>
</div>
</div>
<div id="non-parametric-tests" class="section level2">
<h2><span class="header-section-number">5.3</span> Non-parametric tests</h2>
<p>When should you use non-parametric tests?</p>
<ul>
<li>When your DV is measured on an ordinal scale.</li>
<li>When your data is better represented by the median (e.g., there are outliers that you can’t remove).</li>
<li>When the assumptions of parametric tests are not met (e.g., normally distributed sampling distribution).</li>
<li>You have a very small sample size (i.e., the central limit theorem does not apply).</li>
</ul>
<div id="mann-whitney-u-test-a.k.a.-wilcoxon-rank-sum-test" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Mann-Whitney U Test (a.k.a. Wilcoxon rank-sum test)</h3>
<p>The Mann-Whitney U test is a non-parametric test of differences between groups, similar to the two sample t-test. In contrast to the two sample t-test it only requires ordinally scaled data and relies on weaker assumptions. Thus it is often useful if the assumptions of the t-test are violated, especially if the data is not on a ratio scale, the data is not normally distributed or if the variances can not be assumed to be homogeneous. The following assumptions must be fulfilled for the test to be applicable:</p>
<ul>
<li>The dependent variable is at least ordinally scaled (i.e. a ranking between values can be established).</li>
<li>The independent variable has only two levels.</li>
<li>A between-subjects design is used.</li>
<li>The subjects are not matched across conditions.</li>
</ul>
<p>Intuitively, the test compares the frequency of low and high ranks between groups. Under the null hypothesis, the amount of high and low ranks should be roughly equal in the two groups. This is achieved through comparing the expected sum of ranks to the actual sum of ranks.</p>
<p>The test is implemented in R as the function <code>wilcox.test()</code> and there is no need to compute the ranks before you run the test as the function does this for you. Using the same data on music sales as before the test could be executed as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(unit_sales <span class="op">~</span><span class="st"> </span>group, <span class="dt">data =</span> music_sales)  <span class="co">#Mann-Whitney U Test</span></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  unit_sales by group
## W = 1710, p-value = 0.005374
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>The p-value is smaller than 0.05, which leads us to reject the null hypothesis, i.e. the test yields evidence that the price promotion lead to higher sales.</p>
</div>
<div id="wilcoxon-signed-rank-test" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Wilcoxon signed-rank test</h3>
<p>The Wilcoxon signed-rank test is a non-parametric test used to analyze the difference between paired observations, analogously to the paired t-test. It can be used when measurements come from the same observational units but the distributional assumptions of the paired t-test do not hold, since it does not require any assumptions about the distribution of the measurements. Since we subtract two values, however, the test requires that the dependent variable is at least interval scaled, meaning that intervals have the same meaning for different points on our measurement scale.</p>
<p>Under the null hypothesis, the differences of the measurements should follow a symmetric distribution around 0, meaning that, on average, there is no difference between the two matched samples. H<sub>1</sub> states that the distributions mean is non-zero.</p>
<p>The test can be performed with the same command as the Mann-Whitney U test, provided that the argument <code>paired</code> is set to <code>TRUE</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(music_sales_dep<span class="op">$</span>unit_sales_low_price, music_sales_dep<span class="op">$</span>unit_sales_high_price, 
    <span class="dt">paired =</span> <span class="ot">TRUE</span>)  <span class="co">#Wilcoxon signed-rank test</span></code></pre></div>
<pre><code>## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  music_sales_dep$unit_sales_low_price and music_sales_dep$unit_sales_high_price
## V = 867.5, p-value = 0.004024
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<p>Using the 95% confidence level, the result would suggest a significant effect of price on sales (i.e., p &lt; 0.05).</p>
<p><strong>The following video summarizes how to conduct non-parametric tests in R</strong></p>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/OMQJuXanw-g" frameborder="0" allowfullscreen>
</iframe>
</div>
</div>
</div>
<div id="categorical-data" class="section level2">
<h2><span class="header-section-number">5.4</span> Categorical data</h2>
<div id="comparing-proportions" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Comparing proportions</h3>
<p>In some instances, you will be confronted with differences between proportions, rather than differences between means. For example, you may conduct an A/B-Test and wish to compare the conversion rates between two advertising campaigns. In this case, your data is binary (0 = no conversion, 1 = conversion) and the sampling distribution for such data is binomial. While binomial probabilities are difficult to calculate, we can use a Normal approximation to the binomial when <code>n</code> is large (&gt;100) and the true likelihood of a 1 is not too close to 0 or 1.</p>
<p>Let’s use an example: assume a call center where service agents call potential customers to sell a product. We consider two call center agents:</p>
<ul>
<li>Service agent 1 talks to 300 customers and gets 200 of them to buy (conversion rate=2/3)</li>
<li>Service agent 2 talks to 300 customers and gets 100 of them to buy (conversion rate=1/3)</li>
</ul>
<p>As always, we load the data first:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">call_center &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/call_center.dat&quot;</span>, 
    <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)  <span class="co">#read in data</span>
call_center<span class="op">$</span>conversion &lt;-<span class="st"> </span><span class="kw">factor</span>(call_center<span class="op">$</span>conversion, 
    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;no&quot;</span>, <span class="st">&quot;yes&quot;</span>))  <span class="co">#convert to factor</span>
call_center<span class="op">$</span>agent &lt;-<span class="st"> </span><span class="kw">factor</span>(call_center<span class="op">$</span>agent, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), 
    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;agent_1&quot;</span>, <span class="st">&quot;agent_2&quot;</span>))  <span class="co">#convert to factor</span></code></pre></div>
<p>Next, we create a table to check the relative frequencies:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rel_freq_table &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">prop.table</span>(<span class="kw">table</span>(call_center), 
    <span class="dv">2</span>))  <span class="co">#conditional relative frequencies</span>
rel_freq_table</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["agent"],"name":[1],"type":["fctr"],"align":["left"]},{"label":["conversion"],"name":[2],"type":["fctr"],"align":["left"]},{"label":["Freq"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"agent_1","2":"no","3":"0.3333333"},{"1":"agent_2","2":"no","3":"0.6666667"},{"1":"agent_1","2":"yes","3":"0.6666667"},{"1":"agent_2","2":"yes","3":"0.3333333"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We could also plot the data to visualize the frequencies using ggplot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(rel_freq_table, <span class="kw">aes</span>(<span class="dt">x =</span> agent, <span class="dt">y =</span> Freq, <span class="dt">fill =</span> conversion)) <span class="op">+</span><span class="st"> </span><span class="co">#plot data</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">width =</span> .<span class="dv">7</span>) <span class="op">+</span><span class="st"> </span><span class="co">#position</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">paste0</span>(<span class="kw">round</span>(Freq<span class="op">*</span><span class="dv">100</span>,<span class="dv">0</span>),<span class="st">&quot;%&quot;</span>)), <span class="dt">position =</span> <span class="kw">position_stack</span>(<span class="dt">vjust =</span> <span class="fl">0.5</span>), <span class="dt">size =</span> <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="co">#add percentages</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Proportion of conversions&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;Agent&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># specify axis labels</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-203"></span>
<img src="_main_files/figure-html/unnamed-chunk-203-1.png" alt="proportion of conversions per agent (stacked bar chart)" width="672" />
<p class="caption">
Figure 5.9: proportion of conversions per agent (stacked bar chart)
</p>
</div>
<p>… or using the <code>mosaicplot()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">contigency_table &lt;-<span class="st"> </span><span class="kw">table</span>(call_center)
<span class="kw">mosaicplot</span>(contigency_table, <span class="dt">main =</span> <span class="st">&quot;Proportion of conversions by agent&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-204"></span>
<img src="_main_files/figure-html/unnamed-chunk-204-1.png" alt="proportion of conversions per agent (mosaic plot)" width="672" />
<p class="caption">
Figure 5.10: proportion of conversions per agent (mosaic plot)
</p>
</div>
<p>Recall that we can use confidence intervals to determine the range of values that the true population parameter will take with a certain level of confidence based on the sample. Similar to the confidence interval for means, we can compute a confidence interval for proportions. The (1-α)% confidence interval for proportions is approximately</p>
<span class="math display" id="eq:CIdiff">\[\begin{equation} 
\begin{split}
CI = p\pm z_{1-\frac{\alpha}{2}}*\sqrt{\frac{p*(1-p)}{N}}
\end{split}
\tag{5.18}
\end{equation}\]</span>
<p>where <span class="math inline">\(\sqrt{p(1-p)}\)</span> is the equivalent to the standard deviation in the formula for the confidence interval for means. Based on the equation, it is easy to compute the confidence intervals for the conversion rates of the call center agents:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n1 &lt;-<span class="st"> </span><span class="kw">nrow</span>(<span class="kw">subset</span>(call_center, agent <span class="op">==</span><span class="st"> &quot;agent_1&quot;</span>))  <span class="co">#number of observations for agent 1</span>
n2 &lt;-<span class="st"> </span><span class="kw">nrow</span>(<span class="kw">subset</span>(call_center, agent <span class="op">==</span><span class="st"> &quot;agent_2&quot;</span>))  <span class="co">#number of observations for agent 1</span>
n1_conv &lt;-<span class="st"> </span><span class="kw">nrow</span>(<span class="kw">subset</span>(call_center, agent <span class="op">==</span><span class="st"> &quot;agent_1&quot;</span> <span class="op">&amp;</span><span class="st"> </span>
<span class="st">    </span>conversion <span class="op">==</span><span class="st"> &quot;yes&quot;</span>))  <span class="co">#number of conversions for agent 1</span>
n2_conv &lt;-<span class="st"> </span><span class="kw">nrow</span>(<span class="kw">subset</span>(call_center, agent <span class="op">==</span><span class="st"> &quot;agent_2&quot;</span> <span class="op">&amp;</span><span class="st"> </span>
<span class="st">    </span>conversion <span class="op">==</span><span class="st"> &quot;yes&quot;</span>))  <span class="co">#number of conversions for agent 2</span>
p1 &lt;-<span class="st"> </span>n1_conv<span class="op">/</span>n1  <span class="co">#proportion of conversions for agent 1</span>
p2 &lt;-<span class="st"> </span>n2_conv<span class="op">/</span>n2  <span class="co">#proportion of conversions for agent 2</span>

error1 &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>((p1 <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p1))<span class="op">/</span>n1)
ci_lower1 &lt;-<span class="st"> </span>p1 <span class="op">-</span><span class="st"> </span>error1
ci_upper1 &lt;-<span class="st"> </span>p1 <span class="op">+</span><span class="st"> </span>error1
ci_lower1</code></pre></div>
<pre><code>## [1] 0.6133232</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_upper1</code></pre></div>
<pre><code>## [1] 0.7200101</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">error2 &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>((p2 <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p2))<span class="op">/</span>n2)
ci_lower2 &lt;-<span class="st"> </span>p2 <span class="op">-</span><span class="st"> </span>error2
ci_upper2 &lt;-<span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span>error2
ci_lower2</code></pre></div>
<pre><code>## [1] 0.2799899</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_upper2</code></pre></div>
<pre><code>## [1] 0.3866768</code></pre>
<p>Similar to testing for differences in means, we could also ask: Is agent 1 twice as likely as agent 2 to convert a customer? Or, to state it mathematically:</p>
<p style="text-align:center;">
<span class="math inline">\(H_0: p_1=p_2\)</span><br> <span class="math inline">\(H_1: p_1\ne p_2\)</span>
</p>
<p>One approach to test this is based on confidence intervals to estimate the difference between two populations. We can compute an approximate confidence interval for the difference between the proportion of successes in group 1 and group 2, as:</p>
<span class="math display" id="eq:CIdiff">\[\begin{equation} 
\begin{split}
CI = p_1-p_2\pm z_{1-\frac{\alpha}{2}}*\sqrt{\frac{p_1*(1-p_1)}{n_1}+\frac{p_2*(1-p_2)}{n_2}}
\end{split}
\tag{5.18}
\end{equation}\]</span>
<p>If the confidence interval includes zero, then the data does not suggest a difference between the groups. Let’s compute the confidence interval for differences in the proportions by hand first:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_lower &lt;-<span class="st"> </span>p1 <span class="op">-</span><span class="st"> </span>p2 <span class="op">-</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p1 <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>
<span class="st">    </span>p1)<span class="op">/</span>n1 <span class="op">+</span><span class="st"> </span>p2 <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p2)<span class="op">/</span>n2)  <span class="co">#95% CI lower bound</span>
ci_upper &lt;-<span class="st"> </span>p1 <span class="op">-</span><span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p1 <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>
<span class="st">    </span>p1)<span class="op">/</span>n1 <span class="op">+</span><span class="st"> </span>p2 <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p2)<span class="op">/</span>n2)  <span class="co">#95% CI upper bound</span>
ci_lower</code></pre></div>
<pre><code>## [1] 0.2578943</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_upper</code></pre></div>
<pre><code>## [1] 0.4087724</code></pre>
<p>Now we can see that the 95% confidence interval estimate of the difference between the proportion of conversions for agent 1 and the proportion of conversions for agent 2 is between 26% and 41%. This interval tells us the range of plausible values for the difference between the two population proportions. According to this interval, zero is not a plausible value for the difference (i.e., interval does not cross zero), so we reject the null hypothesis that the population proportions are the same.</p>
<p>Instead of computing the intervals by hand, we could also use the <code>prop.test()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prop.test</span>(<span class="dt">x =</span> <span class="kw">c</span>(n1_conv, n2_conv), <span class="dt">n =</span> <span class="kw">c</span>(n1, n2), <span class="dt">conf.level =</span> <span class="fl">0.95</span>)</code></pre></div>
<pre><code>## 
##  2-sample test for equality of proportions with continuity
##  correction
## 
## data:  c(n1_conv, n2_conv) out of c(n1, n2)
## X-squared = 65.34, df = 1, p-value = 0.0000000000000006303
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  0.2545610 0.4121057
## sample estimates:
##    prop 1    prop 2 
## 0.6666667 0.3333333</code></pre>
<p>Note that the <code>prop.test()</code> function uses a slightly different (more accurate) way to compute the confidence interval (Wilson’s score method is used). It is particularly a better approximation for smaller N. That’s why the confidence interval in the output slightly deviates from the manual computation above, which uses the Wald interval.</p>
<p>You can also see that the output from the <code>prop.test()</code> includes the results from a χ<sup>2</sup> test for the equality of proportions (which will be discussed below) and the associated p-value. Since the p-value is less than 0.05, we reject the null hypothesis of equal probability. Thus, the reporting would be:</p>
<p>The test showed that the conversion rate for agent 1 was higher by 33%. This difference is significant χ (1) = 70, p &lt; .05 (95% CI = [0.25,0.41]).</p>
<p>To <b>calculate the required sample size</b> when comparing proportions, the <code>power.prop.test()</code> function can be used. For example, we could ask how large our sample needs to be if we would like to compare two groups with probabilities of 10% and 15%, respectively using the conventional settings for α and β:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">power.prop.test</span>(<span class="dt">p1 =</span> <span class="fl">0.01</span>, <span class="dt">p2 =</span> <span class="fl">0.15</span>, <span class="dt">sig.level =</span> <span class="fl">0.05</span>, 
    <span class="dt">power =</span> <span class="fl">0.8</span>)</code></pre></div>
<pre><code>## 
##      Two-sample comparison of proportions power calculation 
## 
##               n = 57.75355
##              p1 = 0.01
##              p2 = 0.15
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>The output tells us that we need 58 observations per group to detect a difference of the desired size.</p>
</div>
<div id="chi-square-test" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Chi-square test</h3>
<p>We came across the χ<sup>2</sup> test in the previous section when we used it to test for the equality of proportions. Whenever you would like to investigate the relationship between two categorical variables, the χ<sup>2</sup> test may be used to test whether the variables are independent of each other. It achieves this by comparing the expected number of observations in a group to the actual values. Consider the data set below, where each survey participant either owns an expensive car (coded as a 1) or doesn’t, and either is college educated (coded as a 1) or not. Let’s create the contingency table first:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cross_tab &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/cross_tab.dat&quot;</span>, 
    <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)  <span class="co">#read data</span>
cross_tab<span class="op">$</span>College &lt;-<span class="st"> </span><span class="kw">factor</span>(cross_tab<span class="op">$</span>College, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), 
    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;no&quot;</span>, <span class="st">&quot;yes&quot;</span>))  <span class="co">#convert to factor</span>
cross_tab<span class="op">$</span>CarOwnership &lt;-<span class="st"> </span><span class="kw">factor</span>(cross_tab<span class="op">$</span>CarOwnership, 
    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;no&quot;</span>, <span class="st">&quot;yes&quot;</span>))  <span class="co">#convert to factor</span>
cont_table &lt;-<span class="st"> </span><span class="kw">table</span>(cross_tab)  <span class="co">#create contigency table</span>
cont_table  <span class="co">#view table</span></code></pre></div>
<pre><code>##        CarOwnership
## College  no yes
##     no  590 160
##     yes 170  80</code></pre>
<p>To get a first impression regarding the association between the two variable, we compute the conditional relative frequencies and plot the observed shares by group:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cont_table_df &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">prop.table</span>(<span class="kw">table</span>(cross_tab),<span class="dv">1</span>)) <span class="co">#conditional relative frequencies</span>
cont_table_df</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["College"],"name":[1],"type":["fctr"],"align":["left"]},{"label":["CarOwnership"],"name":[2],"type":["fctr"],"align":["left"]},{"label":["Freq"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"no","2":"no","3":"0.7866667"},{"1":"yes","2":"no","3":"0.6800000"},{"1":"no","2":"yes","3":"0.2133333"},{"1":"yes","2":"yes","3":"0.3200000"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(cont_table_df, <span class="kw">aes</span>(<span class="dt">x =</span> College, <span class="dt">y =</span> Freq, <span class="dt">fill =</span> CarOwnership)) <span class="op">+</span><span class="st"> </span><span class="co">#plot data</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">width =</span> .<span class="dv">7</span>) <span class="op">+</span><span class="st"> </span><span class="co">#position</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">paste0</span>(<span class="kw">round</span>(Freq<span class="op">*</span><span class="dv">100</span>,<span class="dv">0</span>),<span class="st">&quot;%&quot;</span>)), <span class="dt">position =</span> <span class="kw">position_stack</span>(<span class="dt">vjust =</span> <span class="fl">0.5</span>), <span class="dt">size =</span> <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="co">#add percentages</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Expensive car ownership (proportion)&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">&quot;College degree&quot;</span>) <span class="op">+</span><span class="st"> </span><span class="co"># specify axis labels</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-210"></span>
<img src="_main_files/figure-html/unnamed-chunk-210-1.png" alt="Expensive car ownership conditional on college education" width="672" />
<p class="caption">
Figure 5.11: Expensive car ownership conditional on college education
</p>
</div>
<p>Under the null hypothesis, the two variables are independent (i.e., there is no relationship). This means that the frequency in each field will be roughly proportional to the probability of an observation being in that category, calculated under the assumption that they are independent. The difference between that expected quantity and the actual quantity can be used to construct the test statistic. The test statistic is computed as follows:</p>
<span class="math display" id="eq:Chisq">\[\begin{equation} 
\begin{split}
\chi^2=\sum_{i=1}^{J}\frac{(f_o-f_e)^2}{f_e}
\end{split}
\tag{5.19}
\end{equation}\]</span>
<p>where <span class="math inline">\(J\)</span> is the number of cells in the contingency table, <span class="math inline">\(f_o\)</span> are the observed cell frequencies and <span class="math inline">\(f_e\)</span> are the expected cell frequencies. The larger the differences, the larger the test statistic and the smaller the p-value.</p>
<p>The observed cell frequencies can easily be seen from the contingency table:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obs_cell1 &lt;-<span class="st"> </span>cont_table[<span class="dv">1</span>, <span class="dv">1</span>]
obs_cell2 &lt;-<span class="st"> </span>cont_table[<span class="dv">1</span>, <span class="dv">2</span>]
obs_cell3 &lt;-<span class="st"> </span>cont_table[<span class="dv">2</span>, <span class="dv">1</span>]
obs_cell4 &lt;-<span class="st"> </span>cont_table[<span class="dv">2</span>, <span class="dv">2</span>]</code></pre></div>
<p>The expected cell frequencies can be calculated as follows:</p>
<span class="math display" id="eq:fe">\[\begin{equation} 
\begin{split}
f_e=\frac{(n_r*n_c)}{n}
\end{split}
\tag{5.20}
\end{equation}\]</span>
<p>where <span class="math inline">\(n_r\)</span> are the total observed frequencies per row, <span class="math inline">\(n_c\)</span> are the total observed frequencies per column, and <span class="math inline">\(n\)</span> is the total number of observations. Thus, the expected cell frequencies under the assumption of independence can be calculated as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">nrow</span>(cross_tab)
exp_cell1 &lt;-<span class="st"> </span>(<span class="kw">nrow</span>(cross_tab[cross_tab<span class="op">$</span>College <span class="op">==</span><span class="st"> &quot;no&quot;</span>, 
    ]) <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(cross_tab[cross_tab<span class="op">$</span>CarOwnership <span class="op">==</span><span class="st"> &quot;no&quot;</span>, 
    ]))<span class="op">/</span>n
exp_cell2 &lt;-<span class="st"> </span>(<span class="kw">nrow</span>(cross_tab[cross_tab<span class="op">$</span>College <span class="op">==</span><span class="st"> &quot;no&quot;</span>, 
    ]) <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(cross_tab[cross_tab<span class="op">$</span>CarOwnership <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
    ]))<span class="op">/</span>n
exp_cell3 &lt;-<span class="st"> </span>(<span class="kw">nrow</span>(cross_tab[cross_tab<span class="op">$</span>College <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
    ]) <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(cross_tab[cross_tab<span class="op">$</span>CarOwnership <span class="op">==</span><span class="st"> &quot;no&quot;</span>, 
    ]))<span class="op">/</span>n
exp_cell4 &lt;-<span class="st"> </span>(<span class="kw">nrow</span>(cross_tab[cross_tab<span class="op">$</span>College <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
    ]) <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(cross_tab[cross_tab<span class="op">$</span>CarOwnership <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, 
    ]))<span class="op">/</span>n</code></pre></div>
<p>To sum up, these are the expected cell frequencies</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data.frame</span>(<span class="dt">Car_no =</span> <span class="kw">rbind</span>(exp_cell1, exp_cell2), <span class="dt">Car_yes =</span> <span class="kw">rbind</span>(exp_cell3, 
    exp_cell4), <span class="dt">row.names =</span> <span class="kw">c</span>(<span class="st">&quot;College_no&quot;</span>, <span class="st">&quot;College_yes&quot;</span>))</code></pre></div>
<pre><code>##             Car_no Car_yes
## College_no     570     190
## College_yes    180      60</code></pre>
<p>… and these are the observed cell frequencies</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data.frame</span>(<span class="dt">Car_no =</span> <span class="kw">rbind</span>(obs_cell1, obs_cell2), <span class="dt">Car_yes =</span> <span class="kw">rbind</span>(obs_cell3, 
    obs_cell4), <span class="dt">row.names =</span> <span class="kw">c</span>(<span class="st">&quot;College_no&quot;</span>, <span class="st">&quot;College_yes&quot;</span>))</code></pre></div>
<pre><code>##             Car_no Car_yes
## College_no     590     170
## College_yes    160      80</code></pre>
<p>To obtain the test statistic, we simply plug the values into the formula:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chisq_cal &lt;-<span class="st"> </span><span class="kw">sum</span>(((obs_cell1 <span class="op">-</span><span class="st"> </span>exp_cell1)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>exp_cell1), 
    ((obs_cell2 <span class="op">-</span><span class="st"> </span>exp_cell2)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>exp_cell2), ((obs_cell3 <span class="op">-</span><span class="st"> </span>
<span class="st">        </span>exp_cell3)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>exp_cell3), ((obs_cell4 <span class="op">-</span><span class="st"> </span>exp_cell4)<span class="op">^</span><span class="dv">2</span><span class="op">/</span>exp_cell4))
chisq_cal</code></pre></div>
<pre><code>## [1] 11.69591</code></pre>
<p>The test statistic is <span class="math inline">\(\chi^2\)</span> distributed. The chi-square distribution is a non-symmetric distribution. Actually, there are many different chi-square distributions, one for each degree of freedom as show in the following figure.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-216"></span>
<img src="_main_files/figure-html/unnamed-chunk-216-1.png" alt="The chi-square distribution" width="672" />
<p class="caption">
Figure 5.12: The chi-square distribution
</p>
</div>
<p>You can see that as the degrees of freedom increase, the chi-square curve approaches a normal distribution. To find the critical value, we need to specify the corresponding degrees of freedom, given by:</p>
<span class="math display" id="eq:dfchi">\[\begin{equation} 
df=(r-1)*(c-1)
\tag{5.21}
\end{equation}\]</span>
<p>where <span class="math inline">\(r\)</span> is the number of rows and <span class="math inline">\(c\)</span> is the number of columns in the contingency table. Recall that degrees of freedom are generally the number of values that can vary freely when calculating a statistic. In a 2 by 2 table as in our case, we have 2 variables (or two samples) with 2 levels and in each one we have 1 that vary freely. Hence, in our example the degrees of freedom can be calculated as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span>(<span class="kw">nrow</span>(cont_table) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(<span class="kw">ncol</span>(cont_table) <span class="op">-</span><span class="st"> </span>
<span class="st">    </span><span class="dv">1</span>)
df</code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Now, we can derive the critical value given the degrees of freedom and the level of confidence using the <code>qchisq()</code> function and test if the calculated test statistic is larger than the critical value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chisq_crit &lt;-<span class="st"> </span><span class="kw">qchisq</span>(<span class="fl">0.95</span>, df)
chisq_crit</code></pre></div>
<pre><code>## [1] 3.841459</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chisq_cal <span class="op">&gt;</span><span class="st"> </span>chisq_crit</code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-219"></span>
<img src="_main_files/figure-html/unnamed-chunk-219-1.png" alt="Visual depiction of the test result" width="672" />
<p class="caption">
Figure 5.13: Visual depiction of the test result
</p>
</div>
<p>We could also compute the p-value using the <code>pchisq()</code> function, which tells us the probability of the observed cell frequencies if the null hypothesis was true (i.e., there was no association):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p_val &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pchisq</span>(chisq_cal, df)
p_val</code></pre></div>
<pre><code>## [1] 0.0006263775</code></pre>
<p>The test statistic can also be calculated in R directly on the contingency table with the function <code>chisq.test()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(cont_table, <span class="dt">correct =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  cont_table
## X-squared = 11.696, df = 1, p-value = 0.0006264</code></pre>
<p>Since the p-value is smaller than 0.05 (i.e., the calculated test statistic is larger than the critical value), we reject H<sub>0</sub> that the two variables are independent.</p>
<p>Note that the test statistic is sensitive to the sample size. To see this, lets assume that we have a sample of 100 observations instead of 1000 observations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(cont_table<span class="op">/</span><span class="dv">10</span>, <span class="dt">correct =</span> <span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  cont_table/10
## X-squared = 1.1696, df = 1, p-value = 0.2795</code></pre>
<p>You can see that even though the proportions haven’t changed, the test is insignificant now. The following equation let’s you compute a measure of the effect size, which is insensitive to sample size:</p>
<span class="math display" id="eq:fe">\[\begin{equation} 
\begin{split}
\phi=\sqrt{\frac{\chi^2}{n}}
\end{split}
\tag{5.20}
\end{equation}\]</span>
<p>The following guidelines are used to determine the magnitude of the effect size (Cohen, 1988):</p>
<ul>
<li>0.1 (small effect)</li>
<li>0.3 (medium effect)</li>
<li>0.5 (large effect)</li>
</ul>
<p>In our example, we can compute the effect sizes for the large and small samples as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">test_stat &lt;-<span class="st"> </span><span class="kw">chisq.test</span>(cont_table, <span class="dt">correct =</span> <span class="ot">FALSE</span>)<span class="op">$</span>statistic
phi1 &lt;-<span class="st"> </span><span class="kw">sqrt</span>(test_stat<span class="op">/</span>n)
test_stat &lt;-<span class="st"> </span><span class="kw">chisq.test</span>(cont_table<span class="op">/</span><span class="dv">10</span>, <span class="dt">correct =</span> <span class="ot">FALSE</span>)<span class="op">$</span>statistic
phi2 &lt;-<span class="st"> </span><span class="kw">sqrt</span>(test_stat<span class="op">/</span>(n<span class="op">/</span><span class="dv">10</span>))
phi1</code></pre></div>
<pre><code>## X-squared 
## 0.1081476</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">phi2</code></pre></div>
<pre><code>## X-squared 
## 0.1081476</code></pre>
<p>You can see that the statistic is insensitive to the sample size.</p>
<p>Note that the Φ coefficient is appropriate for two dichotomous variables (resulting from a 2 x 2 table as above). If any your nominal variables has more than two categories, Cramér’s V should be used instead:</p>
<span class="math display" id="eq:cramer">\[\begin{equation} 
\begin{split}
V=\sqrt{\frac{\chi^2}{n*df_{min}}}
\end{split}
\tag{5.22}
\end{equation}\]</span>
<p>where <span class="math inline">\(df_{min}\)</span> refers to the degrees of freedom associated with the variable that has fewer categories (e.g., if we have two nominal variables with 3 and 4 categories, <span class="math inline">\(df_{min}\)</span> would be 3 - 1 = 2). The degrees of freedom need to be taken into account when judging the magnitude of the effect sizes (see e.g., <a href="http://www.real-statistics.com/chi-square-and-f-distributions/effect-size-chi-square/" target="_blank">here</a>).</p>
<p>Note that the <code>correct = FALSE</code> argument above ensures that the test statistic is computed in the same way as we have done by hand above. By default, <code>chisq.test()</code> applies a correction to prevent overestimation of statistical significance for small data (called the Yates’ correction). The correction is implemented by subtracting the value 0.5 from the computed difference between the observed and expected cell counts in the numerator of the test statistic (see Equation <a href="hypothesis-testing.html#eq:Chisq">(5.19)</a>). This means that the calculated test statistic will be smaller (i.e., more conservative). Although the adjustment may go too far in some instances, you should generally rely on the adjusted results, which can be computed as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(cont_table)</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  cont_table
## X-squared = 11.118, df = 1, p-value = 0.0008547</code></pre>
<p>As you can see, the results don’t change much in our example, since the differences between the observed and expected cell frequencies are fairly large relative to the correction.</p>
<p>Caution is warranted when the cell counts in the contingency table are small. The usual rule of thumb is that all cell counts should be at least 5 (this may be a little too stringent though). When some cell counts are too small, you can use Fisher’s exact test using the <code>fisher.test()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fisher.test</span>(cont_table)</code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  cont_table
## p-value = 0.0008358
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  1.243392 2.410325
## sample estimates:
## odds ratio 
##   1.734336</code></pre>
<p>The Fisher test, while more conservative, also shows a significant difference between the proportions (p &lt; 0.05). This is not surprising since the cell counts in our example are fairly large.</p>

</div>
</div>
<div id="analysis-of-variance" class="section level2">
<h2><span class="header-section-number">5.5</span> Analysis of variance</h2>
<p>This chapter is primarily based on Field, A., Miles J., &amp; Field, Z. (2012): Discovering Statistics Using R. Sage Publications, <strong>chapters 10 &amp; 12</strong>.</p>
<div id="introduction-1" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Introduction</h3>
<p>In the previous section we learned how to compare means using a t-test. The t-test has some limitations since it only lets you compare 2 means and you can only use it with one independent variable. However, often we would like to compare means from 3 or more groups. In addition, there may be instances in which you manipulate more than one independent variable. For these applications, ANOVA (ANalysis Of VAriance) can be used. Hence, to conduct ANOVA you need:</p>
<ul>
<li>A metric dependent variable (i.e., measured using an interval or ratio scale)</li>
<li>One or more non-metric (categorical) independent variables (also called factors)</li>
</ul>
<p>A treatment is a particular combination of factor levels, or categories. One-way ANOVA is used when there is only one categorical variable (factor). In this case, a treatment is the same as a factor level. N-way ANOVA is used with two or more factors.</p>
<p>Let’s use an example to see how ANOVA works. Assume that you are a marketing manager at an online fashion store, and you wish to analyze the effect of online promotion on sales. You conduct an experiment and select a sample of 30 comparable products to be included in the experiment. Then you randomly assign the products to one of three groups: (1) = high promotion level, (2) = medium promotion level, (3) = low promotion level, and record the sales over one day. This means that you have 10 products assigned to each treatment.</p>
<p>As always, we load and inspect the data first:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">online_store_promo &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/IMSMWU/Teaching/master/MRDA2017/online_store_promo.dat&quot;</span>, 
    <span class="dt">sep =</span> <span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>)  <span class="co">#read in data</span>
online_store_promo<span class="op">$</span>Promotion &lt;-<span class="st"> </span><span class="kw">factor</span>(online_store_promo<span class="op">$</span>Promotion, 
    <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;high&quot;</span>, <span class="st">&quot;medium&quot;</span>, <span class="st">&quot;low&quot;</span>))  <span class="co">#convert grouping variable to factor</span>
<span class="kw">str</span>(online_store_promo)  <span class="co">#inspect data</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    30 obs. of  4 variables:
##  $ Obs       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ Promotion : Factor w/ 3 levels &quot;high&quot;,&quot;medium&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...
##  $ Newsletter: int  1 1 1 1 1 0 0 0 0 0 ...
##  $ Sales     : int  10 9 10 8 9 8 9 7 7 6 ...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(online_store_promo)  <span class="co">#inspect data</span></code></pre></div>
<pre><code>##    Obs Promotion Newsletter Sales
## 1    1      high          1    10
## 2    2      high          1     9
## 3    3      high          1    10
## 4    4      high          1     8
## 5    5      high          1     9
## 6    6      high          0     8
## 7    7      high          0     9
## 8    8      high          0     7
## 9    9      high          0     7
## 10  10      high          0     6
## 11   1    medium          1     8
## 12   2    medium          1     8
## 13   3    medium          1     7
## 14   4    medium          1     9
## 15   5    medium          1     6
## 16   6    medium          0     4
## 17   7    medium          0     5
## 18   8    medium          0     5
## 19   9    medium          0     6
## 20  10    medium          0     4
## 21   1       low          1     5
## 22   2       low          1     7
## 23   3       low          1     6
## 24   4       low          1     4
## 25   5       low          1     5
## 26   6       low          0     2
## 27   7       low          0     3
## 28   8       low          0     2
## 29   9       low          0     1
## 30  10       low          0     2</code></pre>
<p>The null hypothesis, typically, is that all means are equal (non-directional hypothesis). Hence, in our case:</p>
<p style="text-align:center;">
<span class="math inline">\(H_0: \mu_1 = \mu_2 = \mu_3\)</span> <br>
</p>
<p>To get a first impression if there are any differences in sales across the experimental groups, we use the <code>describeBy(...)</code> function from the <code>psych</code> package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(psych)
<span class="kw">describeBy</span>(online_store_promo<span class="op">$</span>Sales, online_store_promo<span class="op">$</span>Promotion)  <span class="co">#inspect data</span></code></pre></div>
<pre><code>## 
##  Descriptive statistics by group 
## group: high
##    vars  n mean   sd median trimmed  mad min max range  skew kurtosis   se
## X1    1 10  8.3 1.34    8.5    8.38 1.48   6  10     4 -0.24     -1.4 0.42
## -------------------------------------------------------- 
## group: medium
##    vars  n mean   sd median trimmed  mad min max range skew kurtosis   se
## X1    1 10  6.2 1.75      6    6.12 2.22   4   9     5 0.17    -1.58 0.55
## -------------------------------------------------------- 
## group: low
##    vars  n mean sd median trimmed  mad min max range skew kurtosis   se
## X1    1 10  3.7  2    3.5    3.62 2.22   1   7     6 0.22    -1.57 0.63</code></pre>
<p>In addition, you should visualize the data using appropriate plots:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Plot of means</span>
<span class="kw">library</span>(plyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(online_store_promo, <span class="kw">aes</span>(Promotion, Sales)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y =</span> mean, <span class="dt">geom =</span> <span class="st">&quot;bar&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;White&quot;</span>, <span class="dt">colour =</span> <span class="st">&quot;Black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> mean_cl_normal, <span class="dt">geom =</span> <span class="st">&quot;pointrange&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Experimental group (promotion level)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Sales (thsd. units)&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-229"></span>
<img src="_main_files/figure-html/unnamed-chunk-229-1.png" alt="Plot of means" width="672" />
<p class="caption">
Figure 5.14: Plot of means
</p>
</div>
<p>Note that ANOVA is an omnibus test, which means that we test for an overall difference between groups. Hence, the test will only tell you if the group means are different, but it won’t tell you exactly which groups are different from another.</p>
<p>So why don’t we then just conduct a series of t-tests for all combinations of groups (i.e., high vs. low, low vs. medium, medium vs. high)? The reason is that if we assume each test to be independent, then there is a 5% probability of falsely rejecting the null hypothesis (Type I error) for each test. In our case:</p>
<ul>
<li>High vs. low (α = 0.05)</li>
<li>High vs. medium (α = 0.05)</li>
<li>Medium vs. low (α = 0.05)</li>
</ul>
<p>This means that the overall probability of making a Type I error is 1-(0.95<sup>3</sup>) = 0.143, since the probability of no Type I error is 0.95 for each of the three tests. Consequently, the Type I error probability would be 14.3%, which is above the conventional standard of 5%. This is also known as the family-wise or experiment-wise error.</p>
</div>
<div id="decomposing-variance" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Decomposing variance</h3>
<p>The basic concept underlying ANOVA is the decomposition of the variance in the data. There are three variance components which we need to consider:</p>
<ul>
<li>We calculate how much variability there is between scores: <b>Total sum of squares (SS<sub>T</sub>)</b></li>
<li>We then calculate how much of this variability can be explained by the model we fit to the data (i.e., how much variability is due to the experimental manipulation): <b>Model sum of squares (SS<sub>M</sub>)</b></li>
<li>… and how much cannot be explained (i.e., how much variability is due to individual differences in performance): <b>Residual sum of squares (SS<sub>R</sub>)</b></li>
</ul>
<p>The following figure shows the different variance components using a generalized data matrix:</p>
<div class="figure">
<img src="https://github.com/IMSMWU/Teaching/raw/master/MRDA2017/sum_of_squares.JPG" alt="Decomposing variance" />
<p class="caption">Decomposing variance</p>
</div>
<p>The total variation is determined by the variation between the categories (due to our experimental manipulation) and the within-category variation that is due to extraneous factors (e.g., differences between the products that are included in each group):</p>
<span class="math display" id="eq:vardecomp">\[\begin{equation} 
\begin{split}
SS_T= SS_M+SS_R
\end{split}
\tag{5.23}
\end{equation}\]</span>
<p>To get a better feeling how this relates to our data set, we can look at the data in a slightly different way. Specifically, we can use the <code>dcast(...)</code> function from the <code>reshape2</code> package to convert the data to wide format:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(reshape2)
<span class="kw">dcast</span>(online_store_promo, Obs <span class="op">~</span><span class="st"> </span>Promotion, <span class="dt">value.var =</span> <span class="st">&quot;Sales&quot;</span>)</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Obs"],"name":[1],"type":["int"],"align":["right"]},{"label":["high"],"name":[2],"type":["int"],"align":["right"]},{"label":["medium"],"name":[3],"type":["int"],"align":["right"]},{"label":["low"],"name":[4],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"10","3":"8","4":"5"},{"1":"2","2":"9","3":"8","4":"7"},{"1":"3","2":"10","3":"7","4":"6"},{"1":"4","2":"8","3":"9","4":"4"},{"1":"5","2":"9","3":"6","4":"5"},{"1":"6","2":"8","3":"4","4":"2"},{"1":"7","2":"9","3":"5","4":"3"},{"1":"8","2":"7","3":"5","4":"2"},{"1":"9","2":"7","3":"6","4":"1"},{"1":"10","2":"6","3":"4","4":"2"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>In this example, X<sub>1</sub> from the generalized data matrix above would refer to the factor level “high”, X<sub>2</sub> to the level “medium”, and X<sub>3</sub> to the level “low”. Y<sub>11</sub> refers to the first data point in the first row (i.e., “10”), Y<sub>12</sub> to the second data point in the first row (i.e., “8”), etc.. The grand mean (<span class="math inline">\(\overline{Y}\)</span>) and the category means (<span class="math inline">\(\overline{Y}_c\)</span>) can be easily computed:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(online_store_promo<span class="op">$</span>Sales)  <span class="co">#grand mean</span></code></pre></div>
<pre><code>## [1] 6.066667</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">by</span>(online_store_promo<span class="op">$</span>Sales, online_store_promo<span class="op">$</span>Promotion, 
    mean)  <span class="co">#category mean</span></code></pre></div>
<pre><code>## online_store_promo$Promotion: high
## [1] 8.3
## -------------------------------------------------------- 
## online_store_promo$Promotion: medium
## [1] 6.2
## -------------------------------------------------------- 
## online_store_promo$Promotion: low
## [1] 3.7</code></pre>
<p>To see how each variance component can be derived, let’s look at the data again. The following graph shows the individual observations by experimental group:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-232"></span>
<img src="_main_files/figure-html/unnamed-chunk-232-1.png" alt="Sum of Squares" width="672" />
<p class="caption">
Figure 5.15: Sum of Squares
</p>
</div>
<div id="total-sum-of-squares" class="section level4">
<h4><span class="header-section-number">5.5.2.1</span> Total sum of squares</h4>
<p>To compute the total variation in the data, we consider the difference between each observation and the grand mean. The grand mean is the mean over all observations in the data set. The vertical lines in the following plot measure how far each observation is away from the grand mean:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-233"></span>
<img src="_main_files/figure-html/unnamed-chunk-233-1.png" alt="Total Sum of Squares" width="672" />
<p class="caption">
Figure 5.16: Total Sum of Squares
</p>
</div>
<p>The formal representation of the total sum of squares (SS<sub>T</sub>) is:</p>
<span class="math display" id="eq:sumsquares">\[\begin{equation} 
\begin{split}
SS_T= \sum_{i=1}^{N} (Y_i-\overline{Y})^2
\end{split}
\tag{5.24}
\end{equation}\]</span>
<p>This means that we need to subtract the grand mean from each individual data point, square the difference, and sum up over all the squared differences. Thus, in our example, the total sum of squares can be calculated as:</p>
<p><span class="math display">\[ 
\begin{align}
SS_T =&amp;(10−6.067)^2 + (9−6.067)^2 + … + (7−6.067)^2\\
      &amp;+(8−6.067)^2 + (8−6.067)^2 + … + (4−6.067)^2\\
      &amp;+(5−6.067)^2 + (7−6.067)^2 + … + (2−6.067)^2\\ 
     =&amp; 185.867
\end{align}
\]</span></p>
<p>You could also compute this in R using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SST &lt;-<span class="st"> </span><span class="kw">sum</span>((online_store_promo<span class="op">$</span>Sales <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(online_store_promo<span class="op">$</span>Sales))<span class="op">^</span><span class="dv">2</span>)
SST</code></pre></div>
<pre><code>## [1] 185.8667</code></pre>
<p>For the subsequent analyses, it is important to understand the concept behind the <b>degrees of freedom</b>. Remember that in order to estimate a population value from a sample, we need to hold something in the population constant. In ANOVA, the df are generally one less than the number of values used to calculate the SS. For example, when we estimate the population mean from a sample, we assume that the sample mean is equal to the population mean. Then, in order to estimate the population mean from the sample, all but one scores are free to vary and the remaining score needs to be the value that keeps the population mean constant. In our example, we used all 30 observations to calculate the sum of square, so the total degrees of freedom (df<sub>T</sub>) are:</p>
<span class="math display" id="eq:dfT">\[\begin{equation} 
\begin{split}
df_T = N-1=30-1=29
\end{split}
\tag{5.25}
\end{equation}\]</span>
</div>
<div id="model-sum-of-squares" class="section level4">
<h4><span class="header-section-number">5.5.2.2</span> Model sum of squares</h4>
<p>Now we know that there are 185.867 units of total variation in our data. Next, we compute how much of the total variation can be explained by the differences between groups (i.e., our experimental manipulation). To compute the explained variation in the data, we consider the difference between the values predicted by our model for each observation (i.e., the group mean) and the grand mean. The group mean refers to the mean value within the experimental group. The vertical lines in the following plot measure how far the predicted value for each observation (i.e., the group mean) is away from the grand mean:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-235"></span>
<img src="_main_files/figure-html/unnamed-chunk-235-1.png" alt="Model Sum of Squares" width="672" />
<p class="caption">
Figure 5.17: Model Sum of Squares
</p>
</div>
<p>The formal representation of the model sum of squares (SS<sub>M</sub>) is:</p>
<span class="math display" id="eq:modelsumsquares">\[\begin{equation} 
\begin{split}
SS_M= \sum_{j=1}^{c} n_j(\overline{Y}_j-\overline{Y})^2
\end{split}
\tag{5.26}
\end{equation}\]</span>
<p>where c denotes the number of categories (experimental groups). This means that we need to subtract the grand mean from each group mean, square the difference, and sum up over all the squared differences. Thus, in our example, the model sum of squares can be calculated as:</p>
<p><span class="math display">\[ 
\begin{align}
SS_M &amp;= 10*(8.3−6.067)^2 + 10*(6.2−6.067)^2 + 10*(3.7−6.067)^2 \\
     &amp;= 106.067
\end{align}
\]</span></p>
<p>You could also compute this manually in R using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSM &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="dv">10</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">by</span>(online_store_promo<span class="op">$</span>Sales, online_store_promo<span class="op">$</span>Promotion, 
    mean) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(online_store_promo<span class="op">$</span>Sales))<span class="op">^</span><span class="dv">2</span>)
SSM</code></pre></div>
<pre><code>## [1] 106.0667</code></pre>
<p>In this case, we used the three group means to calculate the sum of squares, so the model degrees of freedom (df<sub>M</sub>) are:</p>
<span class="math display" id="eq:dfM">\[\begin{equation} 
\begin{split}
df_M= c-1=3-1=2
\end{split}
\tag{5.27}
\end{equation}\]</span>
</div>
<div id="residual-sum-of-squares" class="section level4">
<h4><span class="header-section-number">5.5.2.3</span> Residual sum of squares</h4>
<p>Lastly, we calculate the amount of variation that cannot be explained by our model. In ANOVA, this is the sum of squared distances between what the model predicts for each data point (i.e., the group means) and the observed values. In other words, this refers to the amount of variation that is caused by extraneous factors, such as differences between product characteristics of the products in the different experimental groups. The vertical lines in the following plot measure how far each observation is away from the group mean:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-237"></span>
<img src="_main_files/figure-html/unnamed-chunk-237-1.png" alt="Residual Sum of Squares" width="672" />
<p class="caption">
Figure 5.18: Residual Sum of Squares
</p>
</div>
<p>The formal representation of the residual sum of squares (SS<sub>R</sub>) is:</p>
<span class="math display" id="eq:sumsquaresresid">\[\begin{equation} 
\begin{split}
SS_R= \sum_{j=1}^{c} \sum_{i=1}^{n} ({Y}_{ij}-\overline{Y}_{j})^2
\end{split}
\tag{5.28}
\end{equation}\]</span>
<p>This means that we need to subtract the group mean from each individual observation, square the difference, and sum up over all the squared differences. Thus, in our example, the model sum of squares can be calculated as:</p>
<p><span class="math display">\[ 
\begin{align}
SS_R =&amp; (10−8.3)^2 + (9−8.3)^2 + … + (6−8.3)^2 \\
     &amp;+(8−6.2)^2 + (8−6.2)^2 + … + (4−6.2)^2 \\
     &amp;+ (5−3.7)^2 + (7−3.7)^2 + … + (2−3.7)^2 \\
     =&amp; 79.8
\end{align}
\]</span></p>
<p>You could also compute this in R using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSR &lt;-<span class="st"> </span><span class="kw">sum</span>((online_store_promo<span class="op">$</span>Sales <span class="op">-</span><span class="st"> </span><span class="kw">rep</span>(<span class="kw">by</span>(online_store_promo<span class="op">$</span>Sales, 
    online_store_promo<span class="op">$</span>Promotion, mean), <span class="dt">each =</span> <span class="dv">10</span>))<span class="op">^</span><span class="dv">2</span>)
SSR</code></pre></div>
<pre><code>## [1] 79.8</code></pre>
<p>In this case, we used the 10 values for each of the SS for each group, so the residual degrees of freedom (df<sub>R</sub>) are:</p>
<span class="math display" id="eq:dfR">\[\begin{equation} 
\begin{split}
df_R= (n_1-1)+(n_2-1)+(n_3-1) \\
=(10-1)+(10-1)+(10-1)=27
\end{split}
\tag{5.29}
\end{equation}\]</span>
</div>
<div id="effect-strength" class="section level4">
<h4><span class="header-section-number">5.5.2.4</span> Effect strength</h4>
<p>Once you have computed the different sum of squares, you can investigate the effect strength. Eta<sup>2</sup> is a measure of the variation in Y that is explained by X:</p>
<span class="math display" id="eq:eta">\[\begin{equation} 
\begin{split}
\eta^2= \frac{SS_M}{SS_T}=\frac{106.067}{185.876}=0.571
\end{split}
\tag{5.30}
\end{equation}\]</span>
<p>To compute this in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">eta &lt;-<span class="st"> </span>SSM<span class="op">/</span>SST
eta</code></pre></div>
<pre><code>## [1] 0.57066</code></pre>
<p>The statistic can only take values between 0 and 1. It is equal to 0 when all the category means are equal, indicating that X has no effect on Y. In contrast, it has a value of 1 when there is no variability within each category of X but there is some variability between categories.</p>
</div>
<div id="test-of-significance" class="section level4">
<h4><span class="header-section-number">5.5.2.5</span> Test of significance</h4>
<p>How can we determine whether the effect of X on Y is significant?</p>
<ul>
<li>First, we calculate the fit of the most basic model (i.e., the grand mean)</li>
<li>Then, we calculate the fit of the “best” model (i.e., the group means)</li>
<li>A good model should fit the data significantly better than the basic model</li>
<li>The F-statistic or F-ratio compares the amount of systematic variance in the data to the amount of unsystematic variance</li>
</ul>
<p>The F-statistic uses the ratio of mean square related to X (explained variation) and the mean square related to the error (unexplained variation):</p>
<p style="text-align:center;">
<span class="math inline">\(\frac{SS_M}{SS_R}\)</span> <br>
</p>
<p>However, since these are summed values, their magnitude is influenced by the number of scores that were summed. For example, to calculate SS<sub>M</sub> we only used the sum of 3 values (the group means), while we used 30 and 27 values to calculate SS<sub>T</sub> and SS<sub>R</sub>, respectively. Thus, we calculate the average sum of squares (“mean square”) to compare the average amount of systematic vs. unsystematic variation by dividing the SS values by the degrees of freedom associated with the respective statistic.</p>
<p>Mean square due to X:</p>
<span class="math display" id="eq:MSM">\[\begin{equation} 
\begin{split}
MS_M= \frac{SS_M}{df_M}=\frac{SS_M}{c-1}=\frac{106.067}{(3-1)}
\end{split}
\tag{5.31}
\end{equation}\]</span>
<p>Mean square due to error:</p>
<span class="math display" id="eq:MSR">\[\begin{equation} 
\begin{split}
MS_R= \frac{SS_R}{df_R}=\frac{SS_R}{N-c}=\frac{79.8}{(30-3)}
\end{split}
\tag{5.32}
\end{equation}\]</span>
<p>Now, we compare the amount of variability explained by the model (experiment), to the error in the model (variation due to extraneous variables). If the model explains more variability than it can’t explain, then the experimental manipulation has had a significant effect on the outcome (DV). The F-radio can be derived as follows:</p>
<span class="math display" id="eq:Fstat">\[\begin{equation} 
\begin{split}
F= \frac{MS_M}{MS_R}=\frac{SS_R}{N-c}=\frac{\frac{106.067}{(3-1)}}{\frac{79.8}{(30-3)}}=17.944
\end{split}
\tag{5.33}
\end{equation}\]</span>
<p>You can easily compute this in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_ratio &lt;-<span class="st"> </span>(SSM<span class="op">/</span><span class="dv">2</span>)<span class="op">/</span>(SSR<span class="op">/</span><span class="dv">27</span>)
f_ratio</code></pre></div>
<pre><code>## [1] 17.94361</code></pre>
<p>This statistic follows the F distribution with (m = c – 1) and (n = N – c) degrees of freedom. This means that, like the <span class="math inline">\(\chi^2\)</span> distribution, the shape of the F-distribution depends on the degrees of freedom. In this case, the shape depends on the degrees of freedom associated with the numerator and denominator used to compute the F-ratio. The following figure shows the shape of the F-distribution for different degrees of freedom:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-241"></span>
<img src="_main_files/figure-html/unnamed-chunk-241-1.png" alt="The F distribution" width="672" />
<p class="caption">
Figure 5.19: The F distribution
</p>
</div>
<p>The outcome of the test is one of the following:</p>
<ul>
<li>If the null hypothesis of equal category means is not rejected, then the independent variable does not have a significant effect on the dependent variable</li>
<li>If the null hypothesis is rejected, then the effect of the independent variable is significant</li>
</ul>
<p>For 2 and 27 degrees of freedom, the critical value of F is 3.35 for α=0.05. As usual, you can either look up these values in a table or use the appropriate function in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_crit &lt;-<span class="st"> </span><span class="kw">qf</span>(<span class="fl">0.95</span>, <span class="dt">df1 =</span> <span class="dv">2</span>, <span class="dt">df2 =</span> <span class="dv">27</span>)  <span class="co">#critical value</span>
f_crit</code></pre></div>
<pre><code>## [1] 3.354131</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_ratio <span class="op">&gt;</span><span class="st"> </span>f_crit  <span class="co">#test if calculated test statistic is larger than critical value</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>The output tells us that the calculated test statistic exceeds the critical value. We can also show the test result visually:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-243"></span>
<img src="_main_files/figure-html/unnamed-chunk-243-1.png" alt="Visual depiction of the test result" width="672" />
<p class="caption">
Figure 5.20: Visual depiction of the test result
</p>
</div>
<p>Thus, we conclude that because F<sub>CAL</sub> = 17.944 &gt; F<sub>CR</sub> = 3.35, H<sub>0</sub> is rejected!</p>
<p>Interpretation: one or more of the differences between means are statistically significant.</p>
<p>Reporting: There was a significant effect of promotion on sales levels, F(2,27) = 17.94, p &lt; 0.05, η = 0.571.</p>
<p>Remember: This doesn’t tell us where the differences between groups lie. To find out which group means exactly differ, we need to use post-hoc procedures (see below).</p>
<p>You don’t have to compute these statistics manually! Luckily, there is a function for ANOVA in R, which does the above calculations for you as we will see in the next section.</p>
</div>
</div>
<div id="one-way-anova" class="section level3">
<h3><span class="header-section-number">5.5.3</span> One-way ANOVA</h3>
<div id="basic-anova" class="section level4">
<h4><span class="header-section-number">5.5.3.1</span> Basic ANOVA</h4>
<p>As already indicated, one-way ANOVA is used when there is only one categorical variable (factor). Before conducting ANOVA, you need to check if the assumptions of the test are fulfilled. The assumptions of ANOVA are discussed in the following sections.</p>
<div id="independence-of-observations" class="section level5 unnumbered">
<h5>Independence of observations</h5>
<p>The observations in the groups should be independent. Because we randomly assigned the products to the experimental conditions, this assumption can be assumed to be met.</p>
</div>
<div id="distributional-assumptions" class="section level5 unnumbered">
<h5>Distributional assumptions</h5>
<p>ANOVA is relatively immune to violations to the normality assumption when sample sizes are large due to the Central Limit Theorem. However, if your sample is small (i.e., n &lt; 30 per group) you may nevertheless want to check the normality of your data, e.g., by using the Shapiro-Wilk test or QQ-Plot. In our example, we only have 10 observations per group, which means that we cannot rely on the Central Limit Theorem and we should test the normality of our data. This can be done using the Shapiro-Wilk Test, which has the Null Hypothesis that the data is normally distributed. Hence, an insignificant test results means that the data can be assumed to be approximately normally distributed:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;low&quot;</span>, ]<span class="op">$</span>Sales)</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  online_store_promo[online_store_promo$Promotion == &quot;low&quot;, ]$Sales
## W = 0.93497, p-value = 0.4985</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;medium&quot;</span>, ]<span class="op">$</span>Sales)</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  online_store_promo[online_store_promo$Promotion == &quot;medium&quot;,     ]$Sales
## W = 0.93247, p-value = 0.4726</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;high&quot;</span>, ]<span class="op">$</span>Sales)</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  online_store_promo[online_store_promo$Promotion == &quot;high&quot;, ]$Sales
## W = 0.93185, p-value = 0.4664</code></pre>
<p>Since the test result is insignificant for all groups, we can conclude that the data approximately follow a normal distribution.</p>
<p>We could also test the distributional assumptions visually using a Q-Q plot (i.e., quantile-quantile plot). This plot can be used to assess if a set of data plausibly came from some theoretical distribution such as the Normal distribution. Since this is just a visual check, it is somewhat subjective. But it may help us to judge if our assumption is plausible, and if not, which data points contribute to the violation. A Q-Q plot is a scatterplot created by plotting two sets of quantiles against one another. If both sets of quantiles came from the same distribution, we should see the points forming a line that’s roughly straight. In other words, Q-Q plots take your sample data, sort it in ascending order, and then plot them versus quantiles calculated from a theoretical distribution. Quantiles are often referred to as “percentiles” and refer to the points in your data below which a certain proportion of your data fall. Recall, for example, the standard Normal distribution with a mean of 0 and a standard deviation of 1. Since the 50th percentile (or 0.5 quantile) is 0, half the data lie below 0. The 95th percentile (or 0.95 quantile), is about 1.64, which means that 95 percent of the data lie below 1.64. The 97.5th quantile is about 1.96, which means that 97.5% of the data lie below 1.96. In the Q-Q plot, the number of quantiles is selected to match the size of your sample data.</p>
<p>To create the Q-Q plot for the normal distribution, you may use the <code>qqnorm()</code> function, which takes the data to be tested as an argument. Using the <code>qqline()</code> function subsequently on the data creates the line on which the data points should fall based on the theoretical quantiles. If the individual data points deviate a lot from this line, it means that the data is not likely to follow a normal distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;low&quot;</span>, ]<span class="op">$</span>Sales)
<span class="kw">qqline</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;low&quot;</span>, ]<span class="op">$</span>Sales)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-245"></span>
<img src="_main_files/figure-html/unnamed-chunk-245-1.png" alt="Q-Q plot 1" width="672" />
<p class="caption">
Figure 5.21: Q-Q plot 1
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;medium&quot;</span>, ]<span class="op">$</span>Sales)
<span class="kw">qqline</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;medium&quot;</span>, ]<span class="op">$</span>Sales)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-245"></span>
<img src="_main_files/figure-html/unnamed-chunk-245-2.png" alt="Q-Q plot 2" width="672" />
<p class="caption">
Figure 5.21: Q-Q plot 2
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqnorm</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;high&quot;</span>, ]<span class="op">$</span>Sales)
<span class="kw">qqline</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;high&quot;</span>, ]<span class="op">$</span>Sales)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-245"></span>
<img src="_main_files/figure-html/unnamed-chunk-245-3.png" alt="Q-Q plot 3" width="672" />
<p class="caption">
Figure 5.21: Q-Q plot 3
</p>
</div>
<p>The Q-Q plots suggest an approximately Normal distribution. If the assumption had been violated, you might consider transforming your data or resort to a non-parametric test.</p>
</div>
<div id="homogeneity-of-variance" class="section level5 unnumbered">
<h5>Homogeneity of variance</h5>
<p>You can test the homogeneity of variances in R using Levene’s test:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)
<span class="kw">leveneTest</span>(Sales <span class="op">~</span><span class="st"> </span>Promotion, <span class="dt">data =</span> online_store_promo, 
    <span class="dt">center =</span> mean)</code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = mean)
##       Df F value Pr(&gt;F)
## group  2  1.3532 0.2754
##       27</code></pre>
<p>The null hypothesis of the test is that the group variances are equal. Thus, if the test result is significant it means that the variances are not equal. If we cannot reject the null hypothesis (i.e., the group variances are not significantly different), we can proceed with the ANOVA as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">aov &lt;-<span class="st"> </span><span class="kw">aov</span>(Sales <span class="op">~</span><span class="st"> </span>Promotion, <span class="dt">data =</span> online_store_promo)
<span class="kw">summary</span>(aov)</code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Promotion    2  106.1   53.03   17.94 0.000011 ***
## Residuals   27   79.8    2.96                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>You can see that the p-value is smaller than 0.05. This means that, if there really was no difference between the population means (i.e., the Null hypothesis was true), the probability of the observed differences (or larger differences) is less than 5%.</p>
<p>To compute η<sup>2</sup> from the output, we can extract the relevant sum of squares as follows</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">1</span>]<span class="op">/</span>(<span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">2</span>])</code></pre></div>
<pre><code>## [1] 0.57066</code></pre>
<p>You can see that the results match the results from our manual computation above.</p>
<p>The <code>aov()</code> function also automatically generates some plots that you can use to judge if the model assumptions are met. We will inspect two of the plots here.</p>
<p>We will use the first plot to inspect if the residual variances are equal across the experimental groups:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(aov, <span class="dv">1</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-249-1.png" width="672" /></p>
<p>Generally, the residual variance (i.e., the range of values on the y-axis) should be the same for different levels of our independent variable. The plot shows, that there are some slight differences. Notably, the range of residuals is highest for the “low” group and lowest for the “high” group. However, the differences are not that large and since the Levene’s test could not reject the Null of equal variances, we conclude that the variances are similar enough in this case.</p>
<p>The second plot can be used to test the assumption that the residuals are approximately normally distributed. We use a Q-Q plot to test this assumption:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(aov, <span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-250-1.png" width="672" /></p>
<p>The plot suggests that the residuals are approximately normally distributed. We could also test this by extracting the residuals from the anova output using the <code>resid()</code> function and using the Shapiro-Wilk test:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">shapiro.test</span>(<span class="kw">resid</span>(aov))</code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resid(aov)
## W = 0.96094, p-value = 0.3272</code></pre>
<p>Confirming the impression from the Q-Q plot, we cannot reject the Null that the residuals are approximately normally distributed.</p>
<p>Note that if Levene’s test would have been significant (i.e., variances are not equal), we would have needed to either resort to non-parametric tests (see below), or compute the Welch’s F-ratio instead:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">oneway.test</span>(Sales <span class="op">~</span><span class="st"> </span>Promotion, <span class="dt">data =</span> online_store_promo)</code></pre></div>
<pre><code>## 
##  One-way analysis of means (not assuming equal variances)
## 
## data:  Sales and Promotion
## F = 18.09, num df = 2.00, denom df = 17.47, p-value = 0.00005541</code></pre>
<p>You can see that the results are fairly similar, since the variances turned out to be fairly equal across groups.</p>
</div>
</div>
<div id="post-hoc-tests" class="section level4">
<h4><span class="header-section-number">5.5.3.2</span> Post-hoc tests</h4>
<p>Provided that significant differences were detected by the overall ANOVA you can find out which group means are different using post hoc procedures. Post hoc procedures are designed to conduct pairwise comparisons of all different combinations of the treatment groups by correcting the level of significance for each test such that the overall Type I error rate (α) across all comparisons remains at 0.05.</p>
<p>In other words, we rejected H<sub>0</sub>: μ<sub>1</sub>= μ<sub>2</sub>= μ<sub>3</sub>, and now we would like to test:</p>
<p>Test1:</p>
<p style="text-align:center;">
<span class="math inline">\(H_0: \mu_1 = \mu_2\)</span> <br>
</p>
<p>Test2:</p>
<p style="text-align:center;">
<span class="math inline">\(H_0: \mu_1 = \mu_3\)</span> <br>
</p>
<p>Test3:</p>
<p style="text-align:center;">
<span class="math inline">\(H_0: \mu_2 = \mu_3\)</span> <br>
</p>
<p>There are several post hoc procedures available to choose from. In this tutorial, we will cover Bonferroni and Tukey’s HSD (“honest significant differences”). Both tests control for family-wise error. Bonferroni tends to have more power when the number of comparisons is small, whereas Tukey’ HSDs is better when testing large numbers of means.</p>
<div id="bonferroni" class="section level5">
<h5><span class="header-section-number">5.5.3.2.1</span> Bonferroni</h5>
<p>One of the most popular (and easiest) methods to correct for the family-wise error rate is to conduct the individual t-tests and divide α by the number of comparisons („k“):</p>
<span class="math display" id="eq:pCR">\[\begin{equation} 
\begin{split}
p_{CR}= \frac{\alpha}{k}
\end{split}
\tag{5.34}
\end{equation}\]</span>
<p>In our example with three groups:</p>
<p style="text-align:center;">
<span class="math inline">\(p_{CR}= \frac{0.05}{3}=0.017\)</span> <br>
</p>
<p>Thus, the “corrected” critical p-value is now 0.017 instead of 0.05 (i.e., the critical t value is higher). You can implement the Bonferroni procedure in R using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pairwise.t.test</span>(online_store_promo<span class="op">$</span>Sales, online_store_promo<span class="op">$</span>Promotion, 
    <span class="dt">data =</span> online_store_promo, <span class="dt">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>)</code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  online_store_promo$Sales and online_store_promo$Promotion 
## 
##        high      medium
## medium 0.0329    -     
## low    0.0000066 0.0092
## 
## P value adjustment method: bonferroni</code></pre>
<p>In the output, you will get the corrected p-values for the individual tests. In our example, we can reject H<sub>0</sub> of equal means for all three tests, since p &lt; 0.05 for all combinations of groups.</p>
<p>Note the difference between the results from the post-hoc test compared to individual t-tests. For example, when we test the “medium” vs. “high” groups, the result from a t-test would be:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_subset &lt;-<span class="st"> </span><span class="kw">subset</span>(online_store_promo, Promotion <span class="op">!=</span><span class="st"> </span>
<span class="st">    &quot;low&quot;</span>)
<span class="kw">t.test</span>(Sales <span class="op">~</span><span class="st"> </span>Promotion, <span class="dt">data =</span> data_subset)</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Sales by Promotion
## t = 3.0137, df = 16.834, p-value = 0.007888
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.6287384 3.5712616
## sample estimates:
##   mean in group high mean in group medium 
##                  8.3                  6.2</code></pre>
<p>The p-value is lower in the t-test, reflecting the fact that the family-wise error is not corrected (i.e., the test is less conservative).</p>
</div>
<div id="tukeys-hsd" class="section level5">
<h5><span class="header-section-number">5.5.3.2.2</span> Tukey’s HSD</h5>
<p>Tukey’s HSD also compares all possible pairs of means (two-by-two combinations; i.e., like a t-test, except that it corrects for family-wise error rate).</p>
<p>Test statistic:</p>
<span class="math display" id="eq:tukey">\[\begin{equation} 
\begin{split}
HSD= q\sqrt{\frac{MS_R}{n_c}}
\end{split}
\tag{5.35}
\end{equation}\]</span>
<p>where:</p>
<ul>
<li>q = value from studentized range table (see e.g., <a href="http://www.real-statistics.com/statistics-tables/studentized-range-q-table/" target="_blank">here</a>)</li>
<li>MS<sub>R</sub> = Mean Square Error from ANOVA</li>
<li>n<sub>c</sub> = number of observations per group</li>
<li>Decision: Reject H<sub>0</sub> if</li>
</ul>
<p style="text-align:center;">
<span class="math inline">\(|\overline{Y}_i-\overline{Y}_j | &gt; HSD\)</span> , <br>
</p>
<p>The value from the studentized range table can be obtained using the <code>qtukey()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">q &lt;-<span class="st"> </span><span class="kw">qtukey</span>(<span class="fl">0.95</span>, <span class="dt">nm =</span> <span class="dv">3</span>, <span class="dt">df =</span> <span class="dv">27</span>)
q</code></pre></div>
<pre><code>## [1] 3.506426</code></pre>
<p>Hence:</p>
<p style="text-align:center;">
<span class="math inline">\(HSD= 3.506\sqrt{\frac{2.96}{10}}=1.906\)</span> <br>
</p>
<p>Or, in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hsd &lt;-<span class="st"> </span>q <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Mean Sq&quot;</span>[<span class="dv">2</span>]<span class="op">/</span><span class="dv">10</span>)
hsd</code></pre></div>
<pre><code>## [1] 1.906269</code></pre>
<p>Since all mean differences between groups are larger than 1.906, we can reject the null hypothesis for all individual tests, confirming the results from the Bonferroni test. To compute Tukey’s HSD, we can use the appropriate function from the <code>multcomp</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(multcomp)
tukeys &lt;-<span class="st"> </span><span class="kw">glht</span>(aov, <span class="dt">linfct =</span> <span class="kw">mcp</span>(<span class="dt">Promotion =</span> <span class="st">&quot;Tukey&quot;</span>))
<span class="kw">summary</span>(tukeys)</code></pre></div>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = Sales ~ Promotion, data = online_store_promo)
## 
## Linear Hypotheses:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## medium - high == 0  -2.1000     0.7688  -2.731  0.02850 *  
## low - high == 0     -4.6000     0.7688  -5.983  &lt; 0.001 ***
## low - medium == 0   -2.5000     0.7688  -3.252  0.00826 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(tukeys)</code></pre></div>
<pre><code>## 
##   Simultaneous Confidence Intervals
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = Sales ~ Promotion, data = online_store_promo)
## 
## Quantile = 2.4797
## 95% family-wise confidence level
##  
## 
## Linear Hypotheses:
##                    Estimate lwr     upr    
## medium - high == 0 -2.1000  -4.0065 -0.1935
## low - high == 0    -4.6000  -6.5065 -2.6935
## low - medium == 0  -2.5000  -4.4065 -0.5935</code></pre>
<p>We may also plot the result for the mean differences incl. their confidence intervals:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(tukeys)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-258"></span>
<img src="_main_files/figure-html/unnamed-chunk-258-1.png" alt="Tukey's HSD" width="672" />
<p class="caption">
Figure 5.22: Tukey’s HSD
</p>
</div>
<p>You can see that the CIs do not cross zero, which means that the true difference between group means is unlikely zero.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mean1 &lt;-<span class="st"> </span><span class="kw">mean</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;high&quot;</span>, <span class="st">&quot;Sales&quot;</span>])  <span class="co">#mean group &#39;high&#39;</span>
mean1</code></pre></div>
<pre><code>## [1] 8.3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mean2 &lt;-<span class="st"> </span><span class="kw">mean</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;medium&quot;</span>, <span class="st">&quot;Sales&quot;</span>])  <span class="co">#mean group &#39;medium&#39;</span>
mean2</code></pre></div>
<pre><code>## [1] 6.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mean3 &lt;-<span class="st"> </span><span class="kw">mean</span>(online_store_promo[online_store_promo<span class="op">$</span>Promotion <span class="op">==</span><span class="st"> </span>
<span class="st">    &quot;low&quot;</span>, <span class="st">&quot;Sales&quot;</span>])  <span class="co">#mean group &#39;low&#39;</span>
mean3</code></pre></div>
<pre><code>## [1] 3.7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># CI high vs. medium</span>
mean_diff_high_med &lt;-<span class="st"> </span>mean2 <span class="op">-</span><span class="st"> </span>mean1
mean_diff_high_med</code></pre></div>
<pre><code>## [1] -2.1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_med_high_lower &lt;-<span class="st"> </span>mean_diff_high_med <span class="op">-</span><span class="st"> </span>hsd
ci_med_high_upper &lt;-<span class="st"> </span>mean_diff_high_med <span class="op">+</span><span class="st"> </span>hsd
ci_med_high_lower</code></pre></div>
<pre><code>## [1] -4.006269</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_med_high_upper</code></pre></div>
<pre><code>## [1] -0.1937307</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># CI high vs.low</span>
mean_diff_high_low &lt;-<span class="st"> </span>mean3 <span class="op">-</span><span class="st"> </span>mean1
mean_diff_high_low</code></pre></div>
<pre><code>## [1] -4.6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_low_high_lower &lt;-<span class="st"> </span>mean_diff_high_low <span class="op">-</span><span class="st"> </span>hsd
ci_low_high_upper &lt;-<span class="st"> </span>mean_diff_high_low <span class="op">+</span><span class="st"> </span>hsd
ci_low_high_lower</code></pre></div>
<pre><code>## [1] -6.506269</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_low_high_upper</code></pre></div>
<pre><code>## [1] -2.693731</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># CI medium vs.low</span>
mean_diff_med_low &lt;-<span class="st"> </span>mean3 <span class="op">-</span><span class="st"> </span>mean2
mean_diff_med_low</code></pre></div>
<pre><code>## [1] -2.5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_low_med_lower &lt;-<span class="st"> </span>mean_diff_med_low <span class="op">-</span><span class="st"> </span>hsd
ci_low_med_upper &lt;-<span class="st"> </span>mean_diff_med_low <span class="op">+</span><span class="st"> </span>hsd
ci_low_med_lower</code></pre></div>
<pre><code>## [1] -4.406269</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ci_low_med_upper</code></pre></div>
<pre><code>## [1] -0.5937307</code></pre>
<p>Reporting of post hoc results:</p>
<p>The post hoc tests based on Bonferroni and Tukey’s HSD revealed that sales were significantly higher when using medium vs. low levels, high vs. medium levels, as well high vs. low levels of promotion.</p>
<p><strong>The following video summarizes how to conduct a one-way ANOVA in R</strong></p>
<div align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/vl32om-3KpY" frameborder="0" allowfullscreen>
</iframe>
</div>
</div>
</div>
</div>
<div id="n-way-anova" class="section level3">
<h3><span class="header-section-number">5.5.4</span> N-way ANOVA</h3>
<p>As stated above, N-way ANOVA is used when you have a metric dependent variable and two or more factors with two or more factor levels. In other words, with N-way ANOVA, you can investigate the effects of more than one factor simultaneously. In addition, you can assess interactions between the factors that occur when the effects of one factor on the dependent variable depend on the level (category) of the other factors. An experiment with two or more independent variables is also called a <strong>factorial design</strong> and N-way ANOVA is therefore also referred to as factorial ANOVA.</p>
<p>Let’s extend our example from above and assume that there was a second factor considered in the experiment. Besides the different levels of promotion intensity, the 30 products were also randomly assigned to two experimental groups that determined whether the product was featured in a newsletter or not. Hence, there is a second factor “newsletter” with two factor levels (i.e., “yes” and “no”):</p>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Obs"],"name":[1],"type":["int"],"align":["right"]},{"label":["Promotion"],"name":[2],"type":["fctr"],"align":["left"]},{"label":["Newsletter"],"name":[3],"type":["fctr"],"align":["left"]},{"label":["Sales"],"name":[4],"type":["int"],"align":["right"]}],"data":[{"1":"1","2":"high","3":"yes","4":"10"},{"1":"2","2":"high","3":"yes","4":"9"},{"1":"3","2":"high","3":"yes","4":"10"},{"1":"4","2":"high","3":"yes","4":"8"},{"1":"5","2":"high","3":"yes","4":"9"},{"1":"6","2":"high","3":"no","4":"8"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>This means that we have a 2x3 factorial design since we have one factor with 3 levels (i.e., online promotion (1) “high”, (2) “medium”, (3) “low”), and one factor with 2 levels (i.e., newsletter (1) “yes”, (2) “no”). In a next step, we create a new grouping variable that specifies the treatment using the <code>paste(...)</code> function. The <code>paste(...)</code> function basically concatenates its arguments and separates them by the string given by <code>sep = &quot;&quot;</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">online_store_promo<span class="op">$</span>Group &lt;-<span class="st"> </span><span class="kw">paste</span>(online_store_promo<span class="op">$</span>Promotion, 
    online_store_promo<span class="op">$</span>Newsletter, <span class="dt">sep =</span> <span class="st">&quot;_&quot;</span>)  <span class="co">#create new grouping variable</span>
online_store_promo</code></pre></div>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["Obs"],"name":[1],"type":["int"],"align":["right"]},{"label":["Promotion"],"name":[2],"type":["fctr"],"align":["left"]},{"label":["Newsletter"],"name":[3],"type":["fctr"],"align":["left"]},{"label":["Sales"],"name":[4],"type":["int"],"align":["right"]},{"label":["Group"],"name":[5],"type":["chr"],"align":["left"]}],"data":[{"1":"1","2":"high","3":"yes","4":"10","5":"high_yes"},{"1":"2","2":"high","3":"yes","4":"9","5":"high_yes"},{"1":"3","2":"high","3":"yes","4":"10","5":"high_yes"},{"1":"4","2":"high","3":"yes","4":"8","5":"high_yes"},{"1":"5","2":"high","3":"yes","4":"9","5":"high_yes"},{"1":"6","2":"high","3":"no","4":"8","5":"high_no"},{"1":"7","2":"high","3":"no","4":"9","5":"high_no"},{"1":"8","2":"high","3":"no","4":"7","5":"high_no"},{"1":"9","2":"high","3":"no","4":"7","5":"high_no"},{"1":"10","2":"high","3":"no","4":"6","5":"high_no"},{"1":"1","2":"medium","3":"yes","4":"8","5":"medium_yes"},{"1":"2","2":"medium","3":"yes","4":"8","5":"medium_yes"},{"1":"3","2":"medium","3":"yes","4":"7","5":"medium_yes"},{"1":"4","2":"medium","3":"yes","4":"9","5":"medium_yes"},{"1":"5","2":"medium","3":"yes","4":"6","5":"medium_yes"},{"1":"6","2":"medium","3":"no","4":"4","5":"medium_no"},{"1":"7","2":"medium","3":"no","4":"5","5":"medium_no"},{"1":"8","2":"medium","3":"no","4":"5","5":"medium_no"},{"1":"9","2":"medium","3":"no","4":"6","5":"medium_no"},{"1":"10","2":"medium","3":"no","4":"4","5":"medium_no"},{"1":"1","2":"low","3":"yes","4":"5","5":"low_yes"},{"1":"2","2":"low","3":"yes","4":"7","5":"low_yes"},{"1":"3","2":"low","3":"yes","4":"6","5":"low_yes"},{"1":"4","2":"low","3":"yes","4":"4","5":"low_yes"},{"1":"5","2":"low","3":"yes","4":"5","5":"low_yes"},{"1":"6","2":"low","3":"no","4":"2","5":"low_no"},{"1":"7","2":"low","3":"no","4":"3","5":"low_no"},{"1":"8","2":"low","3":"no","4":"2","5":"low_no"},{"1":"9","2":"low","3":"no","4":"1","5":"low_no"},{"1":"10","2":"low","3":"no","4":"2","5":"low_no"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>As you can see, we now have six experimental groups:</p>
<ol style="list-style-type: decimal">
<li>= high promotion, newsletter</li>
<li>= high promotion, no newsletter</li>
<li>= medium promotion, newsletter</li>
<li>= medium promotion, no newsletter</li>
<li>= low promotion, newsletter</li>
<li>= low promotion, no newsletter</li>
</ol>
<p>In our analysis, we now focus on the comparison of the means between the six groups. Let’s inspect the group means:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">by</span>(online_store_promo<span class="op">$</span>Sales, online_store_promo<span class="op">$</span>Group, 
    mean)  <span class="co">#category means</span></code></pre></div>
<pre><code>## online_store_promo$Group: high_no
## [1] 7.4
## -------------------------------------------------------- 
## online_store_promo$Group: high_yes
## [1] 9.2
## -------------------------------------------------------- 
## online_store_promo$Group: low_no
## [1] 2
## -------------------------------------------------------- 
## online_store_promo$Group: low_yes
## [1] 5.4
## -------------------------------------------------------- 
## online_store_promo$Group: medium_no
## [1] 4.8
## -------------------------------------------------------- 
## online_store_promo$Group: medium_yes
## [1] 7.6</code></pre>
<p>We can also plot the means for each factor individually and for both factors combined.</p>
<p>Plot means for first factor “promotion” (same as before):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Plot of means</span>
<span class="kw">ggplot</span>(online_store_promo, <span class="kw">aes</span>(Promotion, Sales)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y =</span> mean, <span class="dt">geom =</span> <span class="st">&quot;bar&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;White&quot;</span>, <span class="dt">colour=</span><span class="st">&quot;Black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> mean_cl_normal, <span class="dt">geom =</span> <span class="st">&quot;pointrange&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Experimental group (promotion level)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Number of sales&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-263"></span>
<img src="_main_files/figure-html/unnamed-chunk-263-1.png" alt="Plot of means (in-store promotion)" width="672" />
<p class="caption">
Figure 5.23: Plot of means (in-store promotion)
</p>
</div>
<p>Plot means for second factor “newsletter”:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Plot of means</span>
<span class="kw">ggplot</span>(online_store_promo, <span class="kw">aes</span>(Newsletter, Sales)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y =</span> mean, <span class="dt">geom =</span> <span class="st">&quot;bar&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;White&quot;</span>, <span class="dt">colour=</span><span class="st">&quot;Black&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> mean_cl_normal, <span class="dt">geom =</span> <span class="st">&quot;pointrange&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Experimental group (newsletter)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Number of sales&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-264"></span>
<img src="_main_files/figure-html/unnamed-chunk-264-1.png" alt="Plot of means (newsletter)" width="672" />
<p class="caption">
Figure 5.24: Plot of means (newsletter)
</p>
</div>
<p>Plot means for both factors together:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(online_store_promo, <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">interaction</span>(Newsletter, Promotion), <span class="dt">y =</span> Sales, <span class="dt">fill =</span> Newsletter)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y =</span> mean, <span class="dt">geom =</span> <span class="st">&quot;bar&quot;</span>, <span class="dt">position =</span> <span class="kw">position_dodge</span>()) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.data =</span> mean_cl_normal, <span class="dt">geom =</span> <span class="st">&quot;pointrange&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-265"></span>
<img src="_main_files/figure-html/unnamed-chunk-265-1.png" alt="Plot of means (interaction)" width="672" />
<p class="caption">
Figure 5.25: Plot of means (interaction)
</p>
</div>
<p>So what is different compared to the one-way ANOVA? In the one-way ANOVA, we computed the sum of squares as:</p>
<span class="math display" id="eq:vardecomp">\[\begin{equation} 
\begin{split}
SS_T= SS_M+SS_R
\end{split}
\tag{5.23}
\end{equation}\]</span>
<p>The main difference is that in an N-way ANOVA the model sum of squares SS<sub>M</sub> consists of different components. In our case:</p>
<span class="math display" id="eq:SSMn">\[\begin{equation} 
\begin{split}
SS_M= SS_{X_1}+SS_{X_2}+SS_{X_1X_2}
\end{split}
\tag{5.36}
\end{equation}\]</span>
<p>That is, we can further decompose the explained variance into the variance explained by the first factor (X<sub>1</sub>), the variance explained by the second factor (X<sub>2</sub>), and the variance explained by the interaction of these factors (X<sub>1</sub>X<sub>2</sub>). The interaction will tell us if the effect of one factor depends on the level of the second factor and vice versa. Because we now have more information available (the manipulation of the second factor), we would expect the amount of explained variance to increase relative to the amount of unexplained variance.</p>
<p>To visualize this, we can include this new information in the plot that we used before to inspect the model sum of squares:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-266"></span>
<img src="_main_files/figure-html/unnamed-chunk-266-1.png" alt="Sum of Squares (N-way ANOVA)" width="672" />
<p class="caption">
Figure 5.26: Sum of Squares (N-way ANOVA)
</p>
</div>
<p>You can see that our model now better represents the data using the additional information (i.e., the distance between the individual observations and the group mean has decreased). Let’s re-run the ANOVA using the additional information. To do this, we use the same commands as before and simply include the additional factor:</p>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = mean)
##       Df F value Pr(&gt;F)
## group  5   0.689 0.6365
##       24</code></pre>
<pre><code>##                      Df Sum Sq Mean Sq F value        Pr(&gt;F)    
## Promotion             2 106.07   53.03   54.86 0.00000000112 ***
## Newsletter            1  53.33   53.33   55.17 0.00000011439 ***
## Promotion:Newsletter  2   3.27    1.63    1.69         0.206    
## Residuals            24  23.20    0.97                          
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The Levene’s Test indicates that the variances of the groups are not significantly different. Theoretically, you would also need to test the distributional assumptions for each group again, but we skip this step here.</p>
<p>The ANOVA output shows us that the two main effects are significant, while the interaction is not. This means that online promotions and newsletter features result in higher sales. However, the effect of each factor is independent of the other. Note that in the presence of significant interaction effects, it would make no sense to interpret the main effects! If this would be the case, we would only conclude that the effect of one factor depends on the other factor. If the interaction effect is insignificant (as in our case), you could also conduct post hoc tests for each individual factor. However, you only need to conduct post hoc tests for factors with more than 2 levels (i.e., not for the newsletter factor) since there is no family-wise error for variables with two categories.</p>
<p>In an N-way ANOVA, the multiple η<sup>2</sup> measures the strength of the joint effect of two factors (also called the overall effect). To compute the multiple η<sup>2</sup>, the revised equation is:</p>
<span class="math display" id="eq:etan">\[\begin{equation} 
\begin{split}
\eta^2= \frac{SS_{X_1}+SS_{X_2}+SS_{X_1X_2}}{SS_T}
\end{split}
\tag{5.37}
\end{equation}\]</span>
<p>From the output, we can extract the relevant sum of squares as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(<span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">3</span>])<span class="op">/</span>(<span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">3</span>] <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">summary</span>(aov)[[<span class="dv">1</span>]]<span class="op">$</span><span class="st">&quot;Sum Sq&quot;</span>[<span class="dv">4</span>])</code></pre></div>
<pre><code>## [1] 0.8751793</code></pre>
<p>As in the one-way ANOVA, we check the residuals plots generated by R to see if the residuals are approximately normally distributed and whether the residual variance is similar across groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(aov, <span class="dv">1</span>)  <span class="co">#homogeneity of variances</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-269-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(aov, <span class="dv">2</span>)  <span class="co">#normal distribution of residuals</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-269-2.png" width="672" /></p>
<p>Reporting:</p>
<ul>
<li>There was a significant main effect of promotion on sales, F(2,24) = 53.03, p &lt; 0.05.</li>
<li>The post hoc tests based on Bonferroni and Tukey’s HSD revealed that the sales were significantly higher when using medium vs. low levels, high vs. medium levels, as well high vs. low levels of promotion.</li>
<li>There was a significant main effect of newsletter features on sales levels, F(1,24) = 53.33, p &lt; 0.05.<br />
</li>
<li>The effect of each factor is independent of the other since the interaction effect between the level of promotion and direct mailing was insignificant, F(2,24) = 3.27, p &gt; 0.05.</li>
</ul>
</div>
<div id="non-parametric-tests-1" class="section level3">
<h3><span class="header-section-number">5.5.5</span> Non-parametric tests</h3>
<p>When should you use non-parametric tests?</p>
<ul>
<li>When the dependent variable is measured at an ordinal scale and we want to compare more than 2 means</li>
<li>When the assumptions of independent ANOVA are not met (e.g., assumptions regarding the sampling distribution in small samples)</li>
</ul>
<p>The Kruskal–Wallis test is the non-parametric counterpart of the one-way independent ANOVA. It is designed to test for significant differences in population medians when you have more than two samples (otherwise you would use the Mann-Whitney U-test). The theory is very similar to that of the Mann–Whitney U-test since it is also based on ranked data. The Kruskal-Wallis test is carried out using the <code>kruskal.test()</code> function. Using the same data as before, we type:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kruskal.test</span>(Sales <span class="op">~</span><span class="st"> </span>Promotion, <span class="dt">data =</span> online_store_promo)</code></pre></div>
<pre><code>## 
##  Kruskal-Wallis rank sum test
## 
## data:  Sales by Promotion
## Kruskal-Wallis chi-squared = 16.529, df = 2, p-value = 0.0002575</code></pre>
<p>The test-statistic follows a chi-square distribution and since the test is significant (p &lt; 0.05), we can conclude that there are significant differences in population medians. Provided that the overall effect is significant, you may perform a post hoc test to find out which groups are different. To get a first impression, we can plot the data using a boxplot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Boxplot</span>
<span class="kw">ggplot</span>(online_store_promo, <span class="kw">aes</span>(<span class="dt">x =</span> Promotion, <span class="dt">y =</span> Sales)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_boxplot</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Experimental group (promotion level)&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Number of sales&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_bw</span>() </code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-271"></span>
<img src="_main_files/figure-html/unnamed-chunk-271-1.png" alt="Boxplot" width="672" />
<p class="caption">
Figure 5.27: Boxplot
</p>
</div>
<p>To test for differences between groups, we can, for example, apply post hoc tests according to Nemenyi for pairwise multiple comparisons of the ranked data using the appropriate function from the <code>PMCMR</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(PMCMR)
<span class="kw">posthoc.kruskal.nemenyi.test</span>(<span class="dt">x =</span> online_store_promo<span class="op">$</span>Sales, 
    <span class="dt">g =</span> online_store_promo<span class="op">$</span>Promotion, <span class="dt">dist =</span> <span class="st">&quot;Tukey&quot;</span>)</code></pre></div>
<pre><code>## 
##  Pairwise comparisons using Tukey and Kramer (Nemenyi) test  
##                    with Tukey-Dist approximation for independent samples 
## 
## data:  online_store_promo$Sales and online_store_promo$Promotion 
## 
##        high    medium 
## medium 0.09887 -      
## low    0.00016 0.11683
## 
## P value adjustment method: none</code></pre>
<p>The results reveal that there is a significant difference between the “low” and “high” promotion groups. Note that the results are different compared to the results from the parametric test above. This difference occurs because non-parametric tests have more power to detect differences between groups since we loose information by ranking the data. Thus, you should rely on parametric tests if the assumptions are met.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-statistical-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
